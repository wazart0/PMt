{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37332bita337cb3d562a459886fc6e869b497776",
   "display_name": "Python 3.7.3 32-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "34d317d93a37d772ab695795c108f15790d28cc6671edffe18ba0ccb60337721"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atlassian import Jira\n",
    "from bidict import bidict\n",
    "\n",
    "# jira_info = {\n",
    "#     'url': 'https://tangramcare.atlassian.net/',\n",
    "#     'username': 'xxx@ownedoutcomes.com',\n",
    "#     'api_token': 'xxxxxxxxxxxxxxxx',\n",
    "# }\n",
    "\n",
    "jira_info = {\n",
    "    'url': 'https://tangramcare.atlassian.net/',\n",
    "    'username': 'awaz@ownedoutcomes.com',\n",
    "    'api_token': '6Pu9J7zSN4wBqwqgSREsAE08',\n",
    "}\n",
    "\n",
    "# jira_info = {\n",
    "#     'url': 'https://awaz.atlassian.net/',\n",
    "#     'username': 'wazartur@gmail.com',\n",
    "#     'api_token': 'typYw7sWGOPzOLvtq5Z91BDC',\n",
    "# }\n",
    "\n",
    "\n",
    "# jira standard fields config\n",
    "jira_standard_fields = bidict({\n",
    "    'Summary': 'summary',\n",
    "    'Epic': 'customfield_10008',\n",
    "    'Description': 'description',\n",
    "    'Project': 'project',\n",
    "    'Type': 'issuetype',\n",
    "    'Priority': 'priority',\n",
    "    'Labels': 'labels',\n",
    "    'Status': 'status',\n",
    "    'Creator': 'creator',\n",
    "    'Assignee': 'assignee',\n",
    "    'Parent': 'parent',\n",
    "})\n",
    "\n",
    "jira = Jira(\n",
    "            url=jira_info['url'],\n",
    "            username=jira_info['username'],\n",
    "            password=jira_info['api_token'],\n",
    "            cloud=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = jira.jql('project=tt', fields=list(o2_pp_fields.inv.keys()), limit=1000)\n",
    "print(str(issues['maxResults']))\n",
    "print(str(len(issues['issues'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jira.issue_update('PP-329', {\n",
    "            'description': 'check',\n",
    "            'customfield_11701': '2021-03-26',\n",
    "            'customfield_11702': '2021-03-27'\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "\n",
    "workbook = Workbook()\n",
    "sheet = workbook.active\n",
    "\n",
    "sheet[\"A1\"].value = \"Design document:\"\n",
    "sheet[\"C1\"].value = \"Link\"\n",
    "sheet[\"C1\"].hyperlink = \"https://docs.google.com/document/d/1B5RlsVSZdiuKTVAqhrn7xClewqhzrxhliUZd_yIHUBg/edit?usp=sharing\"\n",
    "sheet[\"C1\"].style = \"Hyperlink\"\n",
    "\n",
    "sheet.merge_cells('A3:A4')\n",
    "sheet['A3'].value = 'WBS'\n",
    "\n",
    "sheet.merge_cells('B3:B4')\n",
    "sheet['B3'].value = 'Name'\n",
    "\n",
    "sheet.merge_cells('C3:C4')\n",
    "sheet['C3'].value = 'Description'\n",
    "\n",
    "sheet.merge_cells('D3:D4')\n",
    "sheet['D3'].value = 'Depends on'\n",
    "\n",
    "sheet.merge_cells('E3:G3')\n",
    "sheet['E3'].value = 'Estimated development time [h]'\n",
    "sheet['E4'].value = 'Designer'\n",
    "sheet['F4'].value = 'Reviewer'\n",
    "sheet['G4'].value = 'PM'\n",
    "\n",
    "sheet.merge_cells('H3:H4')\n",
    "sheet['H3'].value = 'Assigned developer'\n",
    "\n",
    "sheet.merge_cells('I3:J3')\n",
    "sheet['I3'].value = 'Estimated testing time [h]'\n",
    "sheet['I4'].value = 'Tester'\n",
    "sheet['J4'].value = 'PM'\n",
    "\n",
    "sheet.merge_cells('K3:K4')\n",
    "sheet['K3'].value = 'Assigned tester'\n",
    "\n",
    "sheet.merge_cells('L3:N3')\n",
    "sheet['L3'].value = 'Actual development time'\n",
    "sheet['L4'].value = 'Start time'\n",
    "sheet['M4'].value = 'Finish time'\n",
    "sheet['N4'].value = 'Duration [h]'\n",
    "\n",
    "sheet.merge_cells('O3:P3')\n",
    "sheet['O3'].value = 'Commit statistics'\n",
    "sheet['O4'].value = 'Insertions'\n",
    "sheet['P4'].value = 'Deletions'\n",
    "\n",
    "sheet.merge_cells('Q3:Q4')\n",
    "sheet['Q3'].value = 'Estimated code documentation time [h]'\n",
    "\n",
    "sheet.merge_cells('R3:R4')\n",
    "sheet['R3'].value = 'Jira ID'\n",
    "\n",
    "sheet.merge_cells('S3:S4')\n",
    "sheet['S3'].value = 'Commit ID'\n",
    "\n",
    "sheet.merge_cells('T3:T4')\n",
    "sheet['T3'].value = 'Comment'\n",
    "\n",
    "\n",
    "workbook.save(filename=\"hello_world.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def datetime_to_date_converter(date):\n",
    "    from datetime import datetime\n",
    "    from dateutil import parser\n",
    "    return parser.parse(date).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def get_schema_from_sheet(sheet): # TODO schema validation\n",
    "    schema = {}\n",
    "    schema['offset_row'] = 1 # offset of WBS: TODO search for WBS\n",
    "    schema['offset_col'] = 0 # offset of WBS: TODO search for WBS\n",
    "    # schema['header_1'] = [i.value for i in sheet['1']] # TODO apply offsets\n",
    "    # schema['header_2'] = [i.value for i in sheet['2']] # TODO apply offsets\n",
    "    # schema['map_to_jira'] = { # TODO something with history (start, finish, duration columns)\n",
    "    #     'Name': 'summary',\n",
    "    #     'Description': 'description',\n",
    "    #     'Jira ID': 'key',\n",
    "    # }\n",
    "\n",
    "\n",
    "    # schema['columns'] = { # TODO make it dynamic\n",
    "    #     'WBS': 'A',\n",
    "    #     'Name': 'B',\n",
    "    #     'Description': 'C',\n",
    "    #     'Depends on': 'D',\n",
    "    #     'Estimate PM': 'G',\n",
    "    #     'Jira ID': 'R',\n",
    "    #     'Start time': 'L',\n",
    "    #     'Finish time': 'M',\n",
    "    #     'Duration [h]': 'N'\n",
    "    # }\n",
    "    # schema['data_offset_row'] = 3\n",
    "    \n",
    "    schema['columns'] = { # TODO make it dynamic\n",
    "        'WBS': 'A',\n",
    "        'Name': 'B',\n",
    "        'Description': 'C',\n",
    "        'Depends on': 'D',\n",
    "        'Estimate PM': 'H',\n",
    "        'Jira ID': 'O',\n",
    "        'Start time': 'J',\n",
    "        'Finish time': 'K',\n",
    "        'Duration [h]': 'L'\n",
    "    }\n",
    "    schema['data_offset_row'] = 3\n",
    "\n",
    "    return schema\n",
    "\n",
    "\n",
    "def get_default_schema_from_template_xlsx(input_template_file = 'template.xlsx', output_schema_file = None):\n",
    "    from openpyxl import load_workbook\n",
    "    import json\n",
    "    workbook = load_workbook(filename=input_template_file)\n",
    "    sheet = workbook['Tasks']\n",
    "\n",
    "    schema = get_schema_from_sheet(sheet)\n",
    "\n",
    "    if output_schema_file == None:\n",
    "        return schema\n",
    "    else:\n",
    "        json.dump(schema, open(output_schema_file, 'w'))\n",
    "\n",
    "\n",
    "def get_issues_from_jira_and_create_xlsx_document_from_template(jira, output_file, project, label, input_template_file = 'template.xlsx'):\n",
    "    from openpyxl import load_workbook\n",
    "    import json\n",
    "    workbook = load_workbook(filename=input_template_file)\n",
    "    sheet = workbook['Tasks']\n",
    "\n",
    "    schema = get_schema_from_sheet(sheet)\n",
    "\n",
    "    issues = jira.jql('project=' + str(project), fields=list(jira_standard_fields.inv.keys()), limit=1000)\n",
    "    # issues = jira.jql('project=' + str(project) + ' and labels=' + str(label), fields=list(jira_standard_fields.inv.keys()), limit=1000)\n",
    "\n",
    "    # TODO\n",
    "\n",
    "\n",
    "def xlsx_to_jira(jira, project, label, input_filename):\n",
    "    from openpyxl import load_workbook\n",
    "    \n",
    "    workbook = load_workbook(filename=input_template_file)\n",
    "    sheet = workbook['Tasks']\n",
    "\n",
    "    schema = get_schema_from_sheet(sheet)\n",
    "    \n",
    "\n",
    "def wbs_regex_check(string, separator = '.'):\n",
    "    import re\n",
    "    return True if re.match('\\A([0-9]+\\\\' + separator + '?)+\\Z', string) else False\n",
    "\n",
    "\n",
    "def wbs_regex_task(string):\n",
    "    import re\n",
    "    return True if re.match('\\A[0-9]+\\Z', string) else False\n",
    "\n",
    "\n",
    "def check_wbs_level(wbs, separator = '.'):\n",
    "    return len(wbs.split(separator))\n",
    "\n",
    "\n",
    "def get_wbs_ancestor(wbs, separator = '.'):\n",
    "    if len(wbs.split(wbs)) == 1:\n",
    "        return wbs.split(wbs)[0]\n",
    "    else:\n",
    "        return '.'.join(wbs.split('.')[0:-1])\n",
    "\n",
    "\n",
    "def check_if_successor(wbs, successor):\n",
    "    wbs_split = wbs.split('.')\n",
    "    successor_split = successor.split('.')\n",
    "    if len(wbs_split) >= len(successor_split):\n",
    "        return False\n",
    "    for i in range(len(wbs_split)):\n",
    "        if wbs_split[i] != successor_split[i]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def get_wbs_lowest_level_task_number(wbs, separator = '.'):\n",
    "    return wbs.split(separator)[-1]\n",
    "\n",
    "\n",
    "def expand_wbs_range(start, finish, separator = '.'):\n",
    "    if check_wbs_level(start, separator) != check_wbs_level(finish, separator):\n",
    "        print('ERROR: WBS range level differs: ', start, ' - ', finish)\n",
    "        return []\n",
    "    if get_wbs_ancestor(start, separator) != get_wbs_ancestor(finish, separator):\n",
    "        print('ERROR: WBS range ancestor differs: ', start, ' - ', finish)\n",
    "        return []\n",
    "    lowest_level_task = list(range(int(get_wbs_lowest_level_task_number(start, separator)), 1 + int(get_wbs_lowest_level_task_number(finish, separator))))\n",
    "    wbs_tasks = []\n",
    "    for i in lowest_level_task:\n",
    "        if get_wbs_ancestor(start, separator) == '':\n",
    "            wbs_tasks.append(str(i))\n",
    "        else:\n",
    "            wbs_tasks.append(get_wbs_ancestor(start, separator) + '.' + str(i))\n",
    "    return wbs_tasks\n",
    "    \n",
    "\n",
    "def parse_dependencies(dependency_str, wbs_separator = '.'):\n",
    "    wbs_tasks = []\n",
    "    for i in str(dependency_str).split(','):\n",
    "        if wbs_regex_check(i.strip(), wbs_separator):\n",
    "            wbs_tasks.append(i)\n",
    "        else:\n",
    "            range = i.split('-')\n",
    "            if len(range) != 2:\n",
    "                print(\"ERROR: It is not a range: \", range)\n",
    "                continue\n",
    "            if wbs_regex_check(range[0].strip(), wbs_separator) == False or wbs_regex_check(range[1].strip(), wbs_separator) == False:\n",
    "                print(\"ERROR: It is not a range: \", range)\n",
    "                continue\n",
    "            wbs_tasks = wbs_tasks + expand_wbs_range(range[0].strip(), range[1].strip(), wbs_separator)\n",
    "    return wbs_tasks\n",
    "\n",
    "\n",
    "def get_value_for_wbs(schema, wbs, column_name):\n",
    "    i = schema['data_offset_row']\n",
    "    while sheet[schema['columns']['WBS'] + str(i)].value is not None:\n",
    "        if wbs == str(sheet[schema['columns']['WBS'] + str(i)].value):\n",
    "            return str(sheet[schema['columns'][column_name] + str(i)].value)\n",
    "        i = i + 1 \n",
    "    return None\n",
    "\n",
    "\n",
    "def get_jira_key_for_wbs(schema, wbs):\n",
    "    i = schema['data_offset_row']\n",
    "    while sheet[schema['columns']['WBS'] + str(i)].value is not None:\n",
    "        if wbs == str(sheet[schema['columns']['WBS'] + str(i)].value):\n",
    "            return str(sheet[schema['columns']['Jira ID'] + str(i)].value)\n",
    "        i = i + 1 \n",
    "    return None\n",
    "\n",
    "\n",
    "def get_start_finish_from_child(schema, wbs):\n",
    "    from dateutil import parser\n",
    "    min = None\n",
    "    max = None\n",
    "    i = schema['data_offset_row']\n",
    "    while sheet[schema['columns']['WBS'] + str(i)].value is not None:\n",
    "        if check_if_successor(wbs, str(sheet[schema['columns']['WBS'] + str(i)].value)):\n",
    "\n",
    "            if min is None and sheet[schema['columns']['Start time'] + str(i)].value is not None:\n",
    "                min = parser.parse(sheet[schema['columns']['Start time'] + str(i)].value)\n",
    "            if max is None and sheet[schema['columns']['Finish time'] + str(i)].value is not None:\n",
    "                max = parser.parse(sheet[schema['columns']['Finish time'] + str(i)].value)\n",
    "\n",
    "            if sheet[schema['columns']['Start time'] + str(i)].value is not None: \n",
    "                if parser.parse(sheet[schema['columns']['Start time'] + str(i)].value) < min:\n",
    "                    min = parser.parse(sheet[schema['columns']['Start time'] + str(i)].value)\n",
    "            if sheet[schema['columns']['Finish time'] + str(i)].value is not None: \n",
    "                if parser.parse(sheet[schema['columns']['Finish time'] + str(i)].value) > max:\n",
    "                    max = parser.parse(sheet[schema['columns']['Finish time'] + str(i)].value)\n",
    "\n",
    "        i = i + 1 \n",
    "    return min, max\n",
    "\n",
    "\n",
    "def get_min_from_start(schema):\n",
    "    from dateutil import parser\n",
    "    min = None\n",
    "    i = schema['data_offset_row']\n",
    "    while sheet[schema['columns']['WBS'] + str(i)].value is not None:\n",
    "        if min is None and sheet[schema['columns']['Start time'] + str(i)].value is not None:\n",
    "            min = parser.parse(sheet[schema['columns']['Start time'] + str(i)].value)\n",
    "\n",
    "        if sheet[schema['columns']['Start time'] + str(i)].value is not None: \n",
    "            if parser.parse(sheet[schema['columns']['Start time'] + str(i)].value) < min:\n",
    "                min = parser.parse(sheet[schema['columns']['Start time'] + str(i)].value)\n",
    "\n",
    "        i = i + 1 \n",
    "    return min\n",
    "\n",
    "\n",
    "def create_or_update_issue(jira, schema, index, project, type, label, parent = None):\n",
    "    if sheet[schema['columns']['Jira ID'] + str(index)].value is None or sheet[schema['columns']['Jira ID'] + str(index)].value == '': # create issue\n",
    "        issue = jira.issue_create({\n",
    "            'summary': sheet[schema['columns']['Name'] + str(index)].value,\n",
    "            'description': sheet[schema['columns']['Description'] + str(index)].value,\n",
    "            'project': {'key': project},\n",
    "            'issuetype': {'name': type},\n",
    "            'parent': {'key': parent},\n",
    "            'customfield_11701': sheet[schema['columns']['Start time'] + str(index)].value,\n",
    "            'customfield_11702': sheet[schema['columns']['Finish time'] + str(index)].value,\n",
    "            # 'customfield_10004': str(float(sheet[schema['columns']['Estimate PM'] + str(index)].value)/4),\n",
    "            # 'Priority': 'priority',\n",
    "            # 'Status': 'status',\n",
    "            # 'Creator': 'creator',\n",
    "            # 'Assignee': 'assignee',\n",
    "        })\n",
    "        sheet[schema['columns']['Jira ID'] + str(index)].value = issue['key']\n",
    "        sheet[schema['columns']['Jira ID'] + str(index)].hyperlink = jira.url + '/browse/' + issue['key']\n",
    "        sheet[schema['columns']['Jira ID'] + str(index)].font = Font(underline='single', color='0000FF')\n",
    "        print(issue)\n",
    "    else:\n",
    "        task_json = {\n",
    "            'summary': sheet[schema['columns']['Name'] + str(index)].value,\n",
    "            'description': sheet[schema['columns']['Description'] + str(index)].value\n",
    "        }\n",
    "\n",
    "        min, max = get_start_finish_from_child(schema, sheet[schema['columns']['WBS'] + str(index)].value)\n",
    "        if min is not None:\n",
    "            task_json['customfield_11701'] = min.strftime(\"%Y-%m-%d\")\n",
    "        if max is not None:\n",
    "            task_json['customfield_11702'] = max.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        if sheet[schema['columns']['Start time'] + str(index)].value is not None and min is None:\n",
    "            task_json['customfield_11701'] = datetime_to_date_converter(sheet[schema['columns']['Start time'] + str(index)].value)\n",
    "        if sheet[schema['columns']['Finish time'] + str(index)].value is not None and max is None:\n",
    "            task_json['customfield_11702'] = datetime_to_date_converter(sheet[schema['columns']['Finish time'] + str(index)].value)\n",
    "\n",
    "        global_min = get_min_from_start(schema)\n",
    "        if 'customfield_11701' not in task_json:\n",
    "            task_json['customfield_11701'] = global_min.strftime(\"%Y-%m-%d\")\n",
    "        if 'customfield_11702' not in task_json:\n",
    "            pass\n",
    "            if sheet[schema['columns']['Estimate PM'] + str(index)].value is not None:\n",
    "                task_json['customfield_11702'] = (global_min + datetime.timedelta(hours = float(sheet[schema['columns']['Estimate PM'] + str(index)].value)*3)).strftime(\"%Y-%m-%d\")\n",
    "            else:\n",
    "                task_json['customfield_11702'] = (global_min + datetime.timedelta(days = 1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "        if sheet[schema['columns']['Duration [h]'] + str(index)].value is not None:\n",
    "            task_json['customfield_10004'] = float(sheet[schema['columns']['Duration [h]'] + str(index)].value)/4\n",
    "        else:\n",
    "            if sheet[schema['columns']['Estimate PM'] + str(index)].value is not None:\n",
    "                task_json['customfield_10004'] = float(sheet[schema['columns']['Estimate PM'] + str(index)].value)/4\n",
    "                \n",
    "        jira.issue_update(sheet[schema['columns']['Jira ID'] + str(index)].value, task_json)\n",
    "\n",
    "    if sheet[schema['columns']['Depends on'] + str(index)].value is not None:\n",
    "        if sheet[schema['columns']['Depends on'] + str(index)].value != '':\n",
    "            for dependent_task_wbs in parse_dependencies(sheet[schema['columns']['Depends on'] + str(index)].value):\n",
    "                fields = {\n",
    "                    \"issuelinks\": [\n",
    "                        {\n",
    "                            \"add\": {\n",
    "                                \"type\": {\n",
    "                                    \"name\": \"Gantt End to Start\",\n",
    "                                    \"inward\": \"has to be done after\",\n",
    "                                    \"outward\": \"has to be done before\"\n",
    "                                },\n",
    "                                \"inwardIssue\": {\n",
    "                                    \"key\": get_jira_key_for_wbs(schema, dependent_task_wbs.strip())\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "                # if get_jira_key_for_wbs(schema, dependent_task_wbs.strip()) is not None or str(get_jira_key_for_wbs(schema, dependent_task_wbs.strip())) != '':\n",
    "                #     jira.edit_issue(issue_id_or_key=sheet[schema['columns']['Jira ID'] + str(index)].value, fields=fields, notify_users=False)\n",
    "    jira.edit_issue(issue_id_or_key=sheet[schema['columns']['Jira ID'] + str(index)].value, fields={\"labels\": [{\"add\": label}]}, notify_users=False)\n",
    "\n",
    "\n",
    "def create_or_update_issues(jira, sheet, schema, project, label):\n",
    "    i = schema['data_offset_row']\n",
    "    while sheet[schema['columns']['WBS'] + str(i)].value is not None:\n",
    "        wbs = str(sheet[schema['columns']['WBS'] + str(i)].value)\n",
    "        if not wbs_regex_check(wbs):\n",
    "            raise Exception('Problem in WBS number structure: ' + str(wbs))\n",
    "\n",
    "        # if wbs_regex_task(wbs):\n",
    "        create_or_update_issue(jira=jira, schema=schema, index=i, project=project, type='Task', label=label)\n",
    "        # else:\n",
    "        #     import re\n",
    "        #     parent = get_jira_key_for_wbs(schema=schema, wbs=re.match('\\A[0-9]+', wbs)[0])\n",
    "        #     if parent is None:\n",
    "        #         raise Exception('Task doesn\\'t have a parent: ' + wbs)\n",
    "        #     create_or_update_issue(jira=jira, schema=schema, index=i, project=project, type='Sub-task', label=label, parent=parent)\n",
    "        # if i > schema['data_offset_row'] + 5: # for tests purposes\n",
    "        #     return\n",
    "        i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font\n",
    "\n",
    "# filename = 'O2 Grouper Pipeline - Task List.xlsx'\n",
    "# label = 'P2_pipelines'\n",
    "\n",
    "filename = 'P2 v3 Replatforming Tasks List.xlsx'\n",
    "label = 'P2_v3'\n",
    "\n",
    "# filename = 'P2 v3 Authorization_DS manager - list of tasks.xlsx'\n",
    "# label = 'Authorization'\n",
    "\n",
    "# filename = 'P2 testing tasks.xlsx'\n",
    "# label = 'Tests'\n",
    "\n",
    "workbook = load_workbook(filename=filename, data_only=True)\n",
    "sheet = workbook['Tasks']\n",
    "\n",
    "schema = get_schema_from_sheet(sheet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Updating issue \"PP-226\" with \"{'summary': 'Analytical API', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-04-14'}\"\n",
      "Updating issue \"PP-247\" with \"{'summary': 'caseSummaryCollection endpoint', 'description': 'This is the basic functionality with filtering but without: benchmarks, pagination or sorting, some response elements are not present in the outputs', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-04-01'}\"\n",
      "Updating issue \"PP-227\" with \"{'summary': 'Implement Filter and derived classes - ColumnFilter, DistanceFilter', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 2.0}\"\n",
      "Updating issue \"PP-228\" with \"{'summary': 'Implement extract_filters for the CaseSummaryFilterInputType input', 'description': None, 'customfield_11701': '2021-02-23', 'customfield_11702': '2021-03-01', 'customfield_10004': 8.0}\"\n",
      "Updating issue \"PP-229\" with \"{'summary': 'Implement extract_filters for the CaseSummaryActionsInputType input', 'description': None, 'customfield_11701': '2021-03-04', 'customfield_11702': '2021-03-11', 'customfield_10004': 3.75}\"\n",
      "Updating issue \"PP-230\" with \"{'summary': 'Implement extract_filters for the RangeInputType input', 'description': None, 'customfield_11701': '2021-03-01', 'customfield_11702': '2021-03-01', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-231\" with \"{'summary': 'Implement filter_by method for pandas.DataFrame with the ColumnFilter', 'description': None, 'customfield_11701': '2021-02-25', 'customfield_11702': '2021-02-26', 'customfield_10004': 1.75}\"\n",
      "Updating issue \"PP-232\" with \"{'summary': 'Implement filter_by method for pandas.DataFrame with the DistanceFilter', 'description': None, 'customfield_11701': '2021-02-26', 'customfield_11702': '2021-03-01', 'customfield_10004': 2.5}\"\n",
      "Updating issue \"PP-307\" with \"{'summary': 'Implement filter_by method for pandas.DataFrame with the RangeFilter', 'description': None, 'customfield_11701': '2021-03-02', 'customfield_11702': '2021-03-02', 'customfield_10004': 0.625}\"\n",
      "Updating issue \"PP-233\" with \"{'summary': 'Implement Node, NodeTypeEnum and NodeSubTypeEnum classes, implement get_node_type_from_subtype method', 'description': None, 'customfield_11701': '2021-02-23', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.75}\"\n",
      "Updating issue \"PP-234\" with \"{'summary': 'Implement PandasProvider class (extending the AnalyticsProvider)', 'description': 'We should be able to pull data from files (available in the project) and join with entities_ac / entities_pac automatically / carelines', 'customfield_11701': '2021-02-23', 'customfield_11702': '2021-02-25', 'customfield_10004': 4.75}\"\n",
      "Updating issue \"PP-308\" with \"{'summary': 'Add computed column fiscal_date to PandasAnalyticalService', 'description': 'fiscal_date = fiscal_year * 10 + fiscal_quarter', 'customfield_11701': '2021-03-02', 'customfield_11702': '2021-03-02', 'customfield_10004': 0.625}\"\n",
      "Updating issue \"PP-235\" with \"{'summary': 'Implement the PandasAnalyticalService find_nodes method', 'description': 'leave other methods unimplemented, all types of nodes should be supported', 'customfield_11701': '2021-03-02', 'customfield_11702': '2021-03-03', 'customfield_10004': 4.0}\"\n",
      "Updating issue \"PP-236\" with \"{'summary': 'Implement AbstractGraphQuery class and make_abstract_graph_query method', 'description': 'for now only implement the methods get_nodes and get_filters, leave the others unimplemented', 'customfield_11701': '2021-03-09', 'customfield_11702': '2021-03-11', 'customfield_10004': 3.75}\"\n",
      "Updating issue \"PP-237\" with \"{'summary': 'Implement AbstractGraphModel class and the make_abstract_graph_model method', 'description': 'for now do not handle the sorting or pagination info', 'customfield_11701': '2021-03-09', 'customfield_11702': '2021-03-11', 'customfield_10004': 3.75}\"\n",
      "Updating issue \"PP-238\" with \"{'summary': 'Implement PandasAnalyticalService group_nodes method', 'description': 'All types of nodes should be supported', 'customfield_11701': '2021-03-04', 'customfield_11702': '2021-03-16', 'customfield_10004': 16.0}\"\n",
      "Updating issue \"PP-239\" with \"{'summary': 'Implement SummaryStatistics class and extract_node_statistics method', 'description': 'All types of nodes should be supported', 'customfield_11701': '2021-03-16', 'customfield_11702': '2021-03-18', 'customfield_10004': 4.5}\"\n",
      "Updating issue \"PP-240\" with \"{'summary': 'Implement extract_relation_statistics method', 'description': 'For now do not extract benchmark_value', 'customfield_11701': '2021-03-19', 'customfield_11702': '2021-03-19', 'customfield_10004': 1.25}\"\n",
      "Updating issue \"PP-241\" with \"{'summary': 'Implement PandasAnalyticalService get_entity_details method', 'description': 'Just pull matching data from entities data frames', 'customfield_11701': '2021-03-08', 'customfield_11702': '2021-03-09', 'customfield_10004': 2.0}\"\n",
      "Updating issue \"PP-242\" with \"{'summary': 'Implement copy_summary_statistics method', 'description': None, 'customfield_11701': '2021-03-18', 'customfield_11702': '2021-03-19', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-502\" with \"{'summary': 'Implement copy_node_details method', 'description': None, 'customfield_11701': '2021-03-24', 'customfield_11702': '2021-03-25', 'customfield_10004': 2.5}\"\n",
      "Updating issue \"PP-243\" with \"{'summary': 'Implement CaseSummaryQueryRunner class', 'description': 'For now ignore the groupingInfo, benchmarkValues, count and legendData responses, ignore benchmark Future argument', 'customfield_11701': '2021-03-22', 'customfield_11702': '2021-03-31', 'customfield_10004': 10.0}\"\n",
      "Updating issue \"PP-575\" with \"{'summary': 'Implement format_case_summary_element method', 'description': None, 'customfield_11701': '2021-03-30', 'customfield_11702': '2021-03-30', 'customfield_10004': 0.5}\"\n",
      "Updating issue \"PP-244\" with \"{'summary': 'implement caseSummaryCollection endpoint', 'description': None, 'customfield_11701': '2021-04-01', 'customfield_11702': '2021-04-01', 'customfield_10004': 1.9375}\"\n",
      "Updating issue \"PP-309\" with \"{'summary': 'Implement get_sql_filter for Node', 'description': 'should return python object', 'customfield_11701': '2021-03-03', 'customfield_11702': '2021-03-04', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-310\" with \"{'summary': 'Implement get_sql_group_column for Node', 'description': 'should return python object', 'customfield_11701': '2021-03-03', 'customfield_11702': '2021-03-04', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-368\" with \"{'summary': 'Implement get_sql_chilld_id column for Node', 'description': None, 'customfield_11701': '2021-03-09', 'customfield_11702': '2021-03-09', 'customfield_10004': 0.25}\"\n",
      "Updating issue \"PP-1014\" with \"{'summary': 'groupingInfo in caseSummaryCollection result', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23'}\"\n",
      "Updating issue \"PP-1007\" with \"{'summary': 'Implement get_grouping_info method', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.25}\"\n",
      "Updating issue \"PP-1008\" with \"{'summary': 'Handle grouping_info argument in copy_node_details, pass grouping_info when calling this method', 'description': 'run get_grouping_info and then use the results', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.875}\"\n",
      "Updating issue \"PP-1015\" with \"{'summary': 'auto-expanding of nodes', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23'}\"\n",
      "Updating issue \"PP-248\" with \"{'summary': 'caseLocationDetails endpoint', 'description': 'For now we ignore the \"state\" output which is likely not used', 'customfield_11701': '2021-03-09', 'customfield_11702': '2021-03-19', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-249\" with \"{'summary': 'implement extract_filters method', 'description': 'The method takes CaseLocationOptionInputType as input, use already existing extract_filters method implementation for the nested types', 'customfield_11701': '2021-03-17', 'customfield_11702': '2021-03-17', 'customfield_10004': 1.75}\"\n",
      "Updating issue \"PP-250\" with \"{'summary': 'implement get_entity_counts method in PandasAnalyticalService', 'description': 'use data frames provided in the examples, calculate statistics both for PACs and hospitals', 'customfield_11701': '2021-03-09', 'customfield_11702': '2021-03-12', 'customfield_10004': 6.0}\"\n",
      "Updating issue \"PP-251\" with \"{'summary': 'implement copy_location_details method', 'description': None, 'customfield_11701': '2021-03-15', 'customfield_11702': '2021-03-17', 'customfield_10004': 4.5}\"\n",
      "Updating issue \"PP-252\" with \"{'summary': 'implement caseLocationDetails endpoint', 'description': None, 'customfield_11701': '2021-03-17', 'customfield_11702': '2021-03-19', 'customfield_10004': 4.0}\"\n",
      "Updating issue \"PP-253\" with \"{'summary': 'caseLobCounts endpoint', 'description': 'see design', 'customfield_11701': '2021-03-11', 'customfield_11702': '2021-03-11', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-254\" with \"{'summary': 'implement get_lob_statistics in PandasAnalyticalService', 'description': None, 'customfield_11701': '2021-03-11', 'customfield_11702': '2021-03-11', 'customfield_10004': 0.25}\"\n",
      "Updating issue \"PP-255\" with \"{'summary': 'implement copy_lob_statistics method', 'description': None, 'customfield_11701': '2021-03-11', 'customfield_11702': '2021-03-11', 'customfield_10004': 0.25}\"\n",
      "Updating issue \"PP-256\" with \"{'summary': 'Implement caseLobCounts endpoint', 'description': 'see design', 'customfield_11701': '2021-03-11', 'customfield_11702': '2021-03-11', 'customfield_10004': 0.25}\"\n",
      "Updating issue \"PP-257\" with \"{'summary': 'getAvailableYears endpoint', 'description': 'see design', 'customfield_11701': '2021-03-12', 'customfield_11702': '2021-03-15', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-258\" with \"{'summary': 'Implement get_all_years method in PandasAnalitycalService', 'description': None, 'customfield_11701': '2021-03-12', 'customfield_11702': '2021-03-15', 'customfield_10004': 0.5}\"\n",
      "Updating issue \"PP-259\" with \"{'summary': 'Implement get_row_range helper method for pandas DF', 'description': None, 'customfield_11701': '2021-03-12', 'customfield_11702': '2021-03-15', 'customfield_10004': 0.5}\"\n",
      "Updating issue \"PP-260\" with \"{'summary': 'Implement getAvailableYears endpoint', 'description': 'see design', 'customfield_11701': '2021-03-12', 'customfield_11702': '2021-03-15', 'customfield_10004': 0.5}\"\n",
      "Updating issue \"PP-261\" with \"{'summary': 'getDateTimeStatsForListOfYears endpoint', 'description': 'see design', 'customfield_11701': '2021-03-11', 'customfield_11702': '2021-03-12', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-262\" with \"{'summary': 'implement get_quarterly_statistics method in PandasAnalyticalService', 'description': None, 'customfield_11701': '2021-03-11', 'customfield_11702': '2021-03-12', 'customfield_10004': 1.25}\"\n",
      "Updating issue \"PP-263\" with \"{'summary': 'implement copy_quarterly_statistics method', 'description': None, 'customfield_11701': '2021-03-11', 'customfield_11702': '2021-03-12', 'customfield_10004': 1.25}\"\n",
      "Updating issue \"PP-264\" with \"{'summary': 'implement getDateTimeStatsForListOfYears endpoint', 'description': 'see design', 'customfield_11701': '2021-03-11', 'customfield_11702': '2021-03-12', 'customfield_10004': 1.25}\"\n",
      "Updating issue \"PP-265\" with \"{'summary': 'implement filteredCareUnitTypes endpoint', 'description': 'see design', 'customfield_11701': '2021-03-05', 'customfield_11702': '2021-03-10', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-285\" with \"{'summary': 'Implement get_careunit_statistics method in PandasAnalyticalService', 'description': None, 'customfield_11701': '2021-03-05', 'customfield_11702': '2021-03-10', 'customfield_10004': 2.25}\"\n",
      "Updating issue \"PP-286\" with \"{'summary': 'Implement extract_careunit_statistics method', 'description': None, 'customfield_11701': '2021-03-05', 'customfield_11702': '2021-03-10', 'customfield_10004': 2.25}\"\n",
      "Updating issue \"PP-265\" with \"{'summary': 'Implement filteredCareUnitTypes endpoint', 'description': 'see design', 'customfield_11701': '2021-03-09', 'customfield_11702': '2021-03-10', 'customfield_10004': 2.25}\"\n",
      "Updating issue \"PP-288\" with \"{'summary': 'implement getDatasetsInitialFilters', 'description': 'see design', 'customfield_11701': '2021-02-25', 'customfield_11702': '2021-03-04', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-289\" with \"{'summary': 'Implement get_diagnose_statistics method in PandasAnalyticalService', 'description': None, 'customfield_11701': '2021-02-25', 'customfield_11702': '2021-03-04', 'customfield_10004': 4.0}\"\n",
      "Updating issue \"PP-290\" with \"{'summary': 'implement copy_diagnose_statistics method', 'description': None, 'customfield_11701': '2021-03-01', 'customfield_11702': '2021-03-04', 'customfield_10004': 4.0}\"\n",
      "Updating issue \"PP-291\" with \"{'summary': 'implement getDatasetsInitialFilters endpoint', 'description': 'use existing queries / methods to populate data in the requested fields', 'customfield_11701': '2021-03-01', 'customfield_11702': '2021-03-04', 'customfield_10004': 4.0}\"\n",
      "Updating issue \"PP-371\" with \"{'summary': 'filteredCareUnits endpoint', 'description': 'see design', 'customfield_11701': '2021-04-08', 'customfield_11702': '2021-04-09', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-375\" with \"{'summary': 'Implement format_careunits method', 'description': None, 'customfield_11701': '2021-04-08', 'customfield_11702': '2021-04-08', 'customfield_10004': 1.25}\"\n",
      "Updating issue \"PP-376\" with \"{'summary': 'Implement filteredCareUnits endpoint', 'description': None, 'customfield_11701': '2021-04-08', 'customfield_11702': '2021-04-09', 'customfield_10004': 2.25}\"\n",
      "Updating issue \"PP-377\" with \"{'summary': 'searchCareUnitAndDetail endpoint', 'description': 'see design', 'customfield_11701': '2021-03-16', 'customfield_11702': '2021-04-06', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-378\" with \"{'summary': 'Implement make_hospital_node', 'description': None, 'customfield_11701': '2021-03-16', 'customfield_11702': '2021-03-17', 'customfield_10004': 0.75}\"\n",
      "Updating issue \"PP-379\" with \"{'summary': 'Implement make_entity_node', 'description': None, 'customfield_11701': '2021-03-16', 'customfield_11702': '2021-03-17', 'customfield_10004': 0.75}\"\n",
      "Updating issue \"PP-380\" with \"{'summary': 'Handle result_set argument in the group_nodes method (inside PandasAnalyticalService)', 'description': 'handle only SHORT and FULL GroupNodesResultSet values', 'customfield_11701': '2021-03-17', 'customfield_11702': '2021-03-17', 'customfield_10004': 0.625}\"\n",
      "Updating issue \"PP-381\" with \"{'summary': 'Modify extract_node_statistics to extract full result', 'description': 'extract 60-day readmission statistics when available', 'customfield_11701': '2021-03-22', 'customfield_11702': '2021-03-22', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-382\" with \"{'summary': 'Implement get_careunit_details method', 'description': None, 'customfield_11701': '2021-03-22', 'customfield_11702': '2021-03-22', 'customfield_10004': 1.5}\"\n",
      "Updating issue \"PP-383\" with \"{'summary': 'Implement get_entity_address in PandasAnalyticalService', 'description': 'provide required datasets', 'customfield_11701': '2021-03-18', 'customfield_11702': '2021-03-19', 'customfield_10004': 4.0}\"\n",
      "Updating issue \"PP-384\" with \"{'summary': 'Implement make_address method', 'description': None, 'customfield_11701': '2021-03-19', 'customfield_11702': '2021-03-19', 'customfield_10004': 0.5}\"\n",
      "Updating issue \"PP-385\" with \"{'summary': 'Implement get_entity_quality in PandasAnalyticalService', 'description': None, 'customfield_11701': '2021-03-31', 'customfield_11702': '2021-04-06', 'customfield_10004': 4.125}\"\n",
      "Updating issue \"PP-386\" with \"{'summary': 'Implement make_quality method', 'description': None, 'customfield_11701': '2021-03-24', 'customfield_11702': '2021-03-24', 'customfield_10004': 0.415}\"\n",
      "Updating issue \"PP-387\" with \"{'summary': 'Implement get_facility_details in PandasAnalyticalService', 'description': None, 'customfield_11701': '2021-04-06', 'customfield_11702': '2021-04-06', 'customfield_10004': 1.25}\"\n",
      "Updating issue \"PP-388\" with \"{'summary': 'Implement make_facility method', 'description': None, 'customfield_11701': '2021-03-24', 'customfield_11702': '2021-03-24', 'customfield_10004': 0.415}\"\n",
      "Updating issue \"PP-389\" with \"{'summary': 'Implement get_entity_staffing in PandasAnalyticalService', 'description': None, 'customfield_11701': '2021-03-23', 'customfield_11702': '2021-03-24', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-390\" with \"{'summary': 'Implement make_staffing method', 'description': None, 'customfield_11701': '2021-03-23', 'customfield_11702': '2021-03-24', 'customfield_10004': 0.415}\"\n",
      "Updating issue \"PP-391\" with \"{'summary': 'Implement searchCareUnitAndDetail endpoint', 'description': None, 'customfield_11701': '2021-04-06', 'customfield_11702': '2021-02-23', 'customfield_10004': 2.5}\"\n",
      "Updating issue \"PP-392\" with \"{'summary': 'getDateTimesForYear endpoint', 'description': 'see design', 'customfield_11701': '2021-03-16', 'customfield_11702': '2021-03-17', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-393\" with \"{'summary': 'Implement find_fiscal_quarters method in PandasAnalyticalService', 'description': None, 'customfield_11701': '2021-03-16', 'customfield_11702': '2021-03-17', 'customfield_10004': 1.25}\"\n",
      "Updating issue \"PP-394\" with \"{'summary': 'Implement getDateTimesForYear endpoint', 'description': None, 'customfield_11701': '2021-03-16', 'customfield_11702': '2021-03-17', 'customfield_10004': 1.25}\"\n",
      "Updating issue \"PP-395\" with \"{'summary': 'Benchmark Calculation', 'description': 'see design', 'customfield_11701': '2021-03-18', 'customfield_11702': '2021-04-14', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-396\" with \"{'summary': 'Implement get_dataset_properties in the DatasetService', 'description': 'see DatasetService design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 2.0}\"\n",
      "ERROR: It is not a range:  ['DM']\n",
      "Updating issue \"PP-397\" with \"{'summary': 'Implement set_dataset_properties in DatasetService', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 2.0}\"\n",
      "ERROR: It is not a range:  ['DM']\n",
      "Updating issue \"PP-398\" with \"{'summary': 'Implement find_datasets in DatasetService', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.0}\"\n",
      "ERROR: It is not a range:  ['DM']\n",
      "Updating issue \"PP-399\" with \"{'summary': 'Implement get_time_range in PandasAnalyticalService', 'description': None, 'customfield_11701': '2021-03-18', 'customfield_11702': '2021-03-19', 'customfield_10004': 2.0}\"\n",
      "Updating issue \"PP-400\" with \"{'summary': 'Implement find_dataset_time_range', 'description': 'use mock DatasetService for tests', 'customfield_11701': '2021-03-19', 'customfield_11702': '2021-03-22', 'customfield_10004': 1.5}\"\n",
      "Updating issue \"PP-401\" with \"{'summary': 'Implement find_benchmark_datasets method', 'description': 'use mock DatasetService for tests', 'customfield_11701': '2021-03-22', 'customfield_11702': '2021-03-24', 'customfield_10004': 5.0}\"\n",
      "Updating issue \"PP-402\" with \"{'summary': 'Implement calculate_benchmark method in PandasAnalyticalService', 'description': 'for now do not implement any special handling of AC_Entity / PAC_Entity nodes, do not handle packed nodes', 'customfield_11701': '2021-03-19', 'customfield_11702': '2021-04-09', 'customfield_10004': 9.625}\"\n",
      "Updating issue \"PP-403\" with \"{'summary': 'Implement get_service_line in PandasAnalyticalService', 'description': None, 'customfield_11701': '2021-03-23', 'customfield_11702': '2021-03-24', 'customfield_10004': 1.5}\"\n",
      "Updating issue \"PP-404\" with \"{'summary': 'Implement get_clinical_episode in PandasAnalyticalService', 'description': None, 'customfield_11701': '2021-03-23', 'customfield_11702': '2021-03-24', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-405\" with \"{'summary': 'Implement get_parent_node method', 'description': None, 'customfield_11701': '2021-03-24', 'customfield_11702': '2021-03-25', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-406\" with \"{'summary': 'Handle parent nodes in calculate_benchmark method', 'description': 'see design', 'customfield_11701': '2021-04-09', 'customfield_11702': '2021-04-13', 'customfield_10004': 5.125}\"\n",
      "Updating issue \"PP-407\" with \"{'summary': 'Implement extract_time_range method', 'description': 'see design', 'customfield_11701': '2021-03-24', 'customfield_11702': '2021-03-24', 'customfield_10004': 0.5}\"\n",
      "Updating issue \"PP-408\" with \"{'summary': 'Implement make_filter (from time range) method', 'description': 'see design', 'customfield_11701': '2021-03-24', 'customfield_11702': '2021-03-24', 'customfield_10004': 0.5}\"\n",
      "Updating issue \"PP-409\" with \"{'summary': 'Extract benchmark_value in extract_relation_statistics method', 'description': 'see design', 'customfield_11701': '2021-03-25', 'customfield_11702': '2021-03-25', 'customfield_10004': 1.5}\"\n",
      "Updating issue \"PP-410\" with \"{'summary': 'Handle benchmark future argument in CaseSummaryQueryRunner', 'description': None, 'customfield_11701': '2021-04-08', 'customfield_11702': '2021-04-09', 'customfield_10004': 3.5}\"\n",
      "Updating issue \"PP-411\" with \"{'summary': 'Integrate benchmark calculations with the caseSummaryCollection query', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-26', 'customfield_10004': 8.0}\"\n",
      "Updating issue \"PP-503\" with \"{'summary': 'Implement handling of packed nodes in calculate_benchmark (use decompose_packed_nodes decorator)', 'description': 'see design, implement a unit test for this use case', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 2.0}\"\n",
      "Updating issue \"PP-704\" with \"{'summary': 'Add source / destination to CaseSummaryType in format_relation_statistics', 'description': 'fix extract_relation_statistics to populate lhs_node and rhs_node in RelationStatistics, then use those members to populate CaseSummaryType in format_relation_statistics', 'customfield_11701': '2021-04-14', 'customfield_11702': '2021-04-14', 'customfield_10004': 0.375}\"\n",
      "Updating issue \"PP-460\" with \"{'summary': 'Node Expand and Collapse', 'description': 'see design', 'customfield_11701': '2021-04-06', 'customfield_11702': '2021-04-06', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-461\" with \"{'summary': 'Implement extract_action method', 'description': 'see design', 'customfield_11701': '2021-04-06', 'customfield_11702': '2021-04-06', 'customfield_10004': 1.5}\"\n",
      "Updating issue \"PP-462\" with \"{'summary': 'Implement make_filter_from_node method', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23'}\"\n",
      "Updating issue \"PP-463\" with \"{'summary': 'Implement extract_filters method', 'description': 'extracting filters from list of actions', 'customfield_11701': '2021-04-06', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-464\" with \"{'summary': 'Integrate expand / collapse functionality with the caseSummaryCollection query', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-26', 'customfield_10004': 8.0}\"\n",
      "Updating issue \"PP-465\" with \"{'summary': 'find_child_nodes', 'description': 'see design', 'customfield_11701': '2021-03-17', 'customfield_11702': '2021-04-01', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-454\" with \"{'summary': 'Implement get_child_node_columns method', 'description': None, 'customfield_11701': '2021-03-17', 'customfield_11702': '2021-03-18', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-455\" with \"{'summary': 'Implement find_child_nodes method in PandasAnalyticalService, for now without sorting', 'description': 'implement first version without sorting or handing other options (dry_run, pagination, match_prefix)', 'customfield_11701': '2021-03-18', 'customfield_11702': '2021-03-18', 'customfield_10004': 1.625}\"\n",
      "Updating issue \"PP-456\" with \"{'summary': 'Handle sorting by case_count in find_child_nodes, add case_count property in Node class', 'description': 'see design, also set case_count property in returned nodes, for now we can allow only sorting by 1 sort criteria', 'customfield_11701': '2021-03-18', 'customfield_11702': '2021-03-19', 'customfield_10004': 1.25}\"\n",
      "Updating issue \"PP-466\" with \"{'summary': 'Handle sorting by options 2 - 7 in find_child_nodes', 'description': 'also handle sorting by multiple columns', 'customfield_11701': '2021-03-22', 'customfield_11702': '2021-03-23', 'customfield_10004': 2.0}\"\n",
      "Updating issue \"PP-467\" with \"{'summary': 'Handle sorting by rating in find_child_nodes', 'description': None, 'customfield_11701': '2021-03-31', 'customfield_11702': '2021-03-31', 'customfield_10004': 0.25}\"\n",
      "Updating issue \"PP-468\" with \"{'summary': 'Handle sorting by name in find_child_nodes', 'description': None, 'customfield_11701': '2021-03-23', 'customfield_11702': '2021-03-23', 'customfield_10004': 1.75}\"\n",
      "Updating issue \"PP-469\" with \"{'summary': 'Handle pagination argument', 'description': 'Limit results to a specific page only', 'customfield_11701': '2021-03-29', 'customfield_11702': '2021-03-29', 'customfield_10004': 0.25}\"\n",
      "Updating issue \"PP-470\" with \"{'summary': 'Handle match_prefix argument', 'description': None, 'customfield_11701': '2021-03-29', 'customfield_11702': '2021-03-29', 'customfield_10004': 0.25}\"\n",
      "Updating issue \"PP-471\" with \"{'summary': 'Handle dry_run option', 'description': 'return int when dry_run = True', 'customfield_11701': '2021-04-01', 'customfield_11702': '2021-04-01', 'customfield_10004': 0.5}\"\n",
      "Updating issue \"PP-472\" with \"{'summary': 'Sorting and Pagination of Nodes', 'description': 'see design', 'customfield_11701': '2021-03-25', 'customfield_11702': '2021-04-09', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-473\" with \"{'summary': 'Implement extract_sort_criteria method', 'description': None, 'customfield_11701': '2021-03-25', 'customfield_11702': '2021-03-26', 'customfield_10004': 1.25}\"\n",
      "Updating issue \"PP-474\" with \"{'summary': 'Implement pack_nodes method, add is_packed() and unpack() methods to Node class', 'description': 'see design, make sure to check performance for ~40k nodes', 'customfield_11701': '2021-03-25', 'customfield_11702': '2021-03-26', 'customfield_10004': 2.0}\"\n",
      "Updating issue \"PP-475\" with \"{'summary': 'Implement extract_pagination method', 'description': None, 'customfield_11701': '2021-03-26', 'customfield_11702': '2021-03-26', 'customfield_10004': 0.5}\"\n",
      "Updating issue \"PP-476\" with \"{'summary': 'Implement get_graph_orientation method', 'description': None, 'customfield_11701': '2021-03-26', 'customfield_11702': '2021-03-29', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-477\" with \"{'summary': 'Implement extract_graph_pagination method', 'description': None, 'customfield_11701': '2021-03-29', 'customfield_11702': '2021-03-29', 'customfield_10004': 0.625}\"\n",
      "Updating issue \"PP-478\" with \"{'summary': 'Update group_nodes method in PandasAnalyticalService to allow a single packed node on either side (and up to 2 pack nodes in total)', 'description': 'see design', 'customfield_11701': '2021-03-26', 'customfield_11702': '2021-04-02', 'customfield_10004': 5.2075}\"\n",
      "Updating issue \"PP-504\" with \"{'summary': 'Handle single packed node on each side in calculate_benchmark method', 'description': 'see also 1.14.6', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-24', 'customfield_10004': 3.0}\"\n",
      "Updating issue \"PP-479\" with \"{'summary': 'Implement decompose_packed_nodes decorator', 'description': 'Apply decorator to all group_nodes implementations (see design), make sure to run queries in parallel', 'customfield_11701': '2021-03-29', 'customfield_11702': '2021-04-06', 'customfield_10004': 1.75}\"\n",
      "Updating issue \"PP-480\" with \"{'summary': 'Refactor make_abstract_graph_query to use find_child_nodes method', 'description': 'pass sorting criteria, see updated design, make sure to run lhs/rhs queries in parallel', 'customfield_11701': '2021-04-07', 'customfield_11702': '2021-04-09', 'customfield_10004': 5.645}\"\n",
      "Updating issue \"PP-481\" with \"{'summary': 'Refactor AbstractGraphModel class and make_abstract_graph_model method to reflect design', 'description': 'make sure to pack nodes according to rules, see design', 'customfield_11701': '2021-03-29', 'customfield_11702': '2021-03-31', 'customfield_10004': 4.125}\"\n",
      "Updating issue \"PP-623\" with \"{'summary': 'Implement make_abstract_graph_model special case to handle pagination (0,0)', 'description': 'see design', 'customfield_11701': '2021-04-06', 'customfield_11702': '2021-04-06', 'customfield_10004': 0.875}\"\n",
      "Updating issue \"PP-482\" with \"{'summary': 'Update caseSummaryCollection endpoint to handle sorting and pagination', 'description': 'make sure sorting and pagination rules are processed, add unit tests for this functionality', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 2.0}\"\n",
      "Updating issue \"PP-483\" with \"{'summary': 'allDatasets endpoint', 'description': 'see design', 'customfield_11701': '2021-03-24', 'customfield_11702': '2021-03-26', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-505\" with \"{'summary': 'define the DatasetDetails class', 'description': None, 'customfield_11701': '2021-03-24', 'customfield_11702': '2021-03-24', 'customfield_10004': 0.25}\"\n",
      "Updating issue \"PP-484\" with \"{'summary': 'Implement get_all_datasets method in the DatasetService class', 'description': 'order by upload_time descending', 'customfield_11701': '2021-04-14', 'customfield_11702': '2021-02-24', 'customfield_10004': 4.0}\"\n",
      "ERROR: It is not a range:  ['DM']\n",
      "Updating issue \"PP-506\" with \"{'summary': 'Implement format_all_datasets_response method', 'description': None, 'customfield_11701': '2021-03-25', 'customfield_11702': '2021-03-25', 'customfield_10004': 0.625}\"\n",
      "Updating issue \"PP-518\" with \"{'summary': 'Implement DummyDatasetService', 'description': 'This is to run P2 application without the actual DM implementation yet, do not implement any unit tests for this class', 'customfield_11701': '2021-03-25', 'customfield_11702': '2021-03-25', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-507\" with \"{'summary': 'Implement allDatasets endpoint', 'description': 'use DummyDatasetService for now', 'customfield_11701': '2021-03-26', 'customfield_11702': '2021-03-26', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-508\" with \"{'summary': 'getLdsDatasetsIds endpoint', 'description': 'see design', 'customfield_11701': '2021-03-29', 'customfield_11702': '2021-03-29', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-509\" with \"{'summary': 'Implement getLDSDatasetsIDs endpoint', 'description': 'use mock DatasetService for now', 'customfield_11701': '2021-03-29', 'customfield_11702': '2021-03-29', 'customfield_10004': 0.25}\"\n",
      "Updating issue \"PP-510\" with \"{'summary': 'dataset endpoint', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-22', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-511\" with \"{'summary': 'Implement get_datasets method in DatasetService', 'description': '1.15.2', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.0}\"\n",
      "ERROR: It is not a range:  ['DM']\n",
      "Updating issue \"PP-512\" with \"{'summary': 'Implement get_pipeline_statistics method in DatasetService', 'description': 'connect to the Pipeline Server', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-25', 'customfield_10004': 6.0}\"\n",
      "ERROR: It is not a range:  ['O2Grouper']\n",
      "Updating issue \"PP-513\" with \"{'summary': 'Implement dataset endpoint', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 2.0}\"\n",
      "Updating issue \"PP-514\" with \"{'summary': 'caseStatistics endpoint', 'description': 'see design', 'customfield_11701': '2021-04-09', 'customfield_11702': '2021-04-12', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-519\" with \"{'summary': 'Implement get_case_statistics in PandasAnalyticalService', 'description': 'Handle sorting and limitation of results', 'customfield_11701': '2021-04-09', 'customfield_11702': '2021-02-26', 'customfield_10004': 8.0}\"\n",
      "Updating issue \"PP-520\" with \"{'summary': 'Implement get_serviceline_benchmarks in PandasAnalyticalService', 'description': 'similar to 1.19.2', 'customfield_11701': '2021-04-13', 'customfield_11702': '2021-02-24', 'customfield_10004': 4.0}\"\n",
      "Updating issue \"PP-521\" with \"{'summary': 'Implement join_serviceline_benchmarks', 'description': 'similar to 1.19.3', 'customfield_11701': '2021-04-12', 'customfield_11702': '2021-04-12', 'customfield_10004': 1.25}\"\n",
      "Updating issue \"PP-522\" with \"{'summary': 'Implement format_case_statistics', 'description': 'Prepare synthetic data frames for unit tests (without and with benchmark values)', 'customfield_11701': '2021-04-12', 'customfield_11702': '2021-04-12', 'customfield_10004': 1.25}\"\n",
      "Updating issue \"PP-523\" with \"{'summary': 'Implement caseStatistics endpoint', 'description': 'see design, make sure to run queries in parallel', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-25', 'customfield_10004': 5.0}\"\n",
      "Updating issue \"PP-515\" with \"{'summary': 'caseSummaryCollectionMapView endpoint', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-22', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-524\" with \"{'summary': 'Implement get_map_view_entity_statistics in PandasAnalyticalService', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-25', 'customfield_10004': 5.0}\"\n",
      "Updating issue \"PP-525\" with \"{'summary': 'Implement get_careunit_benchmarks in PandasAnalyticalService', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-25', 'customfield_10004': 5.0}\"\n",
      "Updating issue \"PP-526\" with \"{'summary': 'Implement join_careunit_benchmarks', 'description': 'Prepare sythetic data frames for the unit test', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-527\" with \"{'summary': 'Implement format_entity_statistics', 'description': 'Prepare synthetic data frames for unit tests (without and with benchmark values)', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-528\" with \"{'summary': 'Implement caseSummaryCollectionMapView endpoint', 'description': 'see design, make sure to run queries in parallel', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-24', 'customfield_10004': 3.0}\"\n",
      "Updating issue \"PP-529\" with \"{'summary': 'Error Handling', 'description': 'see design (to be modified)', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-22', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-530\" with \"{'summary': 'Define ApplicationError base class and app_error_class decorator', 'description': 'just copy from the design and add unit tests', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-22', 'customfield_10004': 0.5}\"\n",
      "Updating issue \"PP-531\" with \"{'summary': \"Review application's code, find all raise statements and throw proper errors\", 'description': 'Declare proper exception classes, define error variables, use DatasetNotFound as a model example, place all errors in the errors.py module', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-27', 'customfield_10004': 9.0}\"\n",
      "Updating issue \"PP-532\" with \"{'summary': 'Add list of error codes and descriptions to technical design', 'description': 'This task is development driven', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-533\" with \"{'summary': 'Backend Configuration', 'description': 'see design', 'customfield_11701': '2021-04-12', 'customfield_11702': '2021-04-12', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-534\" with \"{'summary': 'Implement AppConfig singleton', 'description': 'Define ConfigVariables and defaults, validate configuration on first access to AppConfig', 'customfield_11701': '2021-04-12', 'customfield_11702': '2021-04-12', 'customfield_10004': 1.75}\"\n",
      "Updating issue \"PP-537\" with \"{'summary': 'Data Suppression (LDS-11 rule)', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-22', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-1016\" with \"{'summary': 'Implement get_aggregation_level method', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.75}\"\n",
      "Updating issue \"PP-1017\" with \"{'summary': 'Add LDS_SUPPRESSION_ENABLED flag to AppConfig', 'description': 'allow False only in DEBUG deployment mode', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-22', 'customfield_10004': 0.5}\"\n",
      "Updating issue \"PP-1018\" with \"{'summary': 'Handle __lds_suppress_aggregation_level member in select_from_relations method from SQLAnalyticalService', 'description': 'implement suppression logic, read tutorial', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-26', 'customfield_10004': 7.0}\"\n",
      "Updating issue \"PP-1019\" with \"{'summary': 'Modify open method in SQLAnalyticsProvider', 'description': 'pass lds_tables argument to SQLAnalyticalService and forward lds_suppress_aggregation_level, see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.75}\"\n",
      "Updating issue \"PP-1020\" with \"{'summary': 'Integrate LDS suppression rules with the caseSummaryCollection endpoint', 'description': 'use get_aggregation_level method and pass its result to open in the AnalyticsProvider, implement unit tests to check if proper aggregation level is passed for various queries, check LDS_SUPPRESSION_ENABLED flag', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.5}\"\n",
      "Updating issue \"PP-1021\" with \"{'summary': 'Integrate with other endpoints', 'description': 'Review all places where the method \"open\" from AnalyticsProvider is being called, pass lds_suppress_aggregation_level argument where it makes sense', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-24', 'customfield_10004': 3.0}\"\n",
      "Updating issue \"PP-1022\" with \"{'summary': 'Implement is_suppressed method in SQLAnalyticalService', 'description': 'define new method in AnalyticalService base class, always return False from the PandasAnalyticalService', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-22', 'customfield_10004': 0.375}\"\n",
      "Updating issue \"PP-1023\" with \"{'summary': 'Return isSuppressed flag in caseSummaryCollection result', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.75}\"\n",
      "Updating issue \"PP-538\" with \"{'summary': 'User Dataset Upload', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23'}\"\n",
      "Updating issue \"PP-1024\" with \"{'summary': 'Add PIPELINE_SERVER_URL variable to AppConfig', 'description': 'only required in RELEASE deployments', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-22', 'customfield_10004': 0.25}\"\n",
      "Updating issue \"PP-942\" with \"{'summary': 'Implement add_uploaded_file in Repository class', 'description': 'see design, define repository data model (use Django), add Repository instance to context (available to endpoint resolvers)', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 2.5}\"\n",
      "Updating issue \"PP-943\" with \"{'summary': 'Implement set_error method in Repository class', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-22', 'customfield_10004': 0.375}\"\n",
      "Updating issue \"PP-944\" with \"{'summary': 'Implement set_s3_url method in Repository class', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-22', 'customfield_10004': 0.375}\"\n",
      "Updating issue \"PP-945\" with \"{'summary': 'Implement set_pipeline_id in Repository class', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-22', 'customfield_10004': 0.375}\"\n",
      "Updating issue \"PP-1025\" with \"{'summary': 'Implement AppProcessPool class', 'description': 'just copy code from the design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-22', 'customfield_10004': 0.25}\"\n",
      "Updating issue \"PP-1026\" with \"{'summary': 'Implement start_o2_grouper method', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.75}\"\n",
      "Updating issue \"PP-1027\" with \"{'summary': 'Implement upload_to_s3_and_start_o2_grouper method', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23'}\"\n",
      "Updating issue \"PP-1028\" with \"{'summary': 'Implement sendfile/upload_file endpoint', 'description': 'copy from P2 v2 backend, run upload_to_s3_and_start_o2_grouper form in a separate process task and return immediately', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 2.5}\"\n",
      "Updating issue \"PP-1029\" with \"{'summary': 'Implement has_s3_put_object_permission method', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.75}\"\n",
      "Updating issue \"PP-1030\" with \"{'summary': 'Validate s3:PutObject permission on start-up (in RELEASE deployment mode only)', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.625}\"\n",
      "Updating issue \"PP-1031\" with \"{'summary': 'Implement get_user_uploaded_files method in Repository class', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.75}\"\n",
      "Updating issue \"PP-1032\" with \"{'summary': 'Update format_all_datasets_response method to take into account upload_status field in DatasetDetails (Validation, Failed or Finished)', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.75}\"\n",
      "Updating issue \"PP-1033\" with \"{'summary': 'Update allDatasets endpoint to include currently processed and failed processing files', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.125}\"\n",
      "Updating issue \"PP-1034\" with \"{'summary': 'Implement get_uploaded_file in Repository', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.75}\"\n",
      "Updating issue \"PP-1035\" with \"{'summary': 'Update get_datasets method in DatasetService', 'description': 'handle uploaded file ids, see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.5}\"\n",
      "Updating issue \"PP-539\" with \"{'summary': 'Snowflake Integration', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23'}\"\n",
      "Updating issue \"PP-946\" with \"{'summary': 'Implement SQLConnectionFactory and SQLConnection', 'description': 'implement connect and close methods, define and use connection configuration variables', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 2.0}\"\n",
      "Updating issue \"PP-947\" with \"{'summary': 'Implement get_sql_column method', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.625}\"\n",
      "Updating issue \"PP-948\" with \"{'summary': 'Implement make_sql_filter (for ColumnFilter) method', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-949\" with \"{'summary': 'Implement make_sql_filter (for RangeFilter) method', 'description': 'make sure to handle special \"fiscal_date\" column name', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-950\" with \"{'summary': 'Implement make_sql_distance_filter method', 'description': 'or_ combine from AC and PAC entities', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-951\" with \"{'summary': 'Implement select_from_relations in SQLAnalyticalService', 'description': 'define SQLAnalyticalService class, handle unions, joined tables and additional columns, raise error from unimplemented interface methods, ignore lds_suppress_aggregation_level argument', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-24', 'customfield_10004': 3.5}\"\n",
      "Updating issue \"PP-952\" with \"{'summary': 'Implement DataCommons class', 'description': 'see design, implement validation of all datasets', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-24', 'customfield_10004': 4.5}\"\n",
      "Updating issue \"PP-953\" with \"{'summary': 'Implement get_datasets method in DatasetService', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-24', 'customfield_10004': 3.0}\"\n",
      "ERROR: It is not a range:  ['DM']\n",
      "Updating issue \"PP-954\" with \"{'summary': 'Implement SQLAnalyticsProvider', 'description': 'see design, always query DatasetService, make sure to cache Tables, use mocked DatasetService for tests', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23'}\"\n",
      "Updating issue \"PP-955\" with \"{'summary': 'Handle backend type selection from configuration', 'description': 'Check BACKEND_TYPE configuration variable to create either PandasAnalyticsProvider and mocked DatasetService or SQLAnalyticsProvider and real DatasetService', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 2.5}\"\n",
      "Updating issue \"PP-956\" with \"{'summary': 'Implement find_child_nodes is SQLAnalyticalService', 'description': 'handle all arguments, use pandas implementation as example', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-25', 'customfield_10004': 6.0}\"\n",
      "Updating issue \"PP-957\" with \"{'summary': 'Implement group_nodes in SQLAnalyticalService', 'description': 'see pandas implementation as example', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-26', 'customfield_10004': 8.0}\"\n",
      "Updating issue \"PP-958\" with \"{'summary': 'Implement get_entity_details in SQLAnalyticalService', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.75}\"\n",
      "Updating issue \"PP-959\" with \"{'summary': 'Implement get_entity_counts in SQLAnalyticalService', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-24', 'customfield_10004': 3.0}\"\n",
      "Updating issue \"PP-960\" with \"{'summary': 'Implement get_lob_statistics in SQLAnalyticalService', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.75}\"\n",
      "Updating issue \"PP-961\" with \"{'summary': 'Implement get_quarterly_statistics in SQLAnalyticalService', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.75}\"\n",
      "Updating issue \"PP-962\" with \"{'summary': 'Implement get_careunit_statistics in SQLAnalyticalService', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.75}\"\n",
      "Updating issue \"PP-963\" with \"{'summary': 'Implement get_diagnose_statistics in SQLAnalyticalService', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.75}\"\n",
      "Updating issue \"PP-964\" with \"{'summary': 'Implement find_fiscal_quarters in SQLAnalyticalService', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-22', 'customfield_10004': 0.5}\"\n",
      "Updating issue \"PP-965\" with \"{'summary': 'Implement get_time_range in SQLAnalyticalService', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.75}\"\n",
      "Updating issue \"PP-966\" with \"{'summary': 'Implement calculate_benchmark in SQLAnalyticalService', 'description': 'see pandas implementation as example', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-26', 'customfield_10004': 8.0}\"\n",
      "Updating issue \"PP-967\" with \"{'summary': 'Implement get_entity_address in SQLAnalyticalService', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-968\" with \"{'summary': 'Implement get_entity_quality in SQLAnalyticalService', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.5}\"\n",
      "Updating issue \"PP-969\" with \"{'summary': 'Implement get_facility_details in SQLAnalyticalService', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.5}\"\n",
      "Updating issue \"PP-970\" with \"{'summary': 'Implement get_entity_staffing in SQLAnalyticalService', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-971\" with \"{'summary': 'Impement get_service_unit_ids method in DataCommons', 'description': 'see design, make sure to cache results', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-972\" with \"{'summary': 'Implement get_service_line in SQLAnalyticalService', 'description': 'use get_service_unit_ids and resolve the ID mapping from its result', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-22', 'customfield_10004': 0.375}\"\n",
      "Updating issue \"PP-973\" with \"{'summary': 'Implement get_clinical_episode in SQLAnalyticalService', 'description': 'use get_service_unit_ids and resolve the ID mapping from its result', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-22', 'customfield_10004': 0.375}\"\n",
      "Updating issue \"PP-974\" with \"{'summary': 'Implement get_map_view_entity_statistics in SQLAnalyticalService', 'description': 'see pandas implementation as example', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 2.5}\"\n",
      "Updating issue \"PP-975\" with \"{'summary': 'Implement get_case_statistics in SQLAnalyticalService', 'description': 'see pandas implementation as example', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-24', 'customfield_10004': 3.0}\"\n",
      "Updating issue \"PP-976\" with \"{'summary': 'Implement get_serviceline_benchmarks in SQLAnalyticalService', 'description': 'see pandas implementation as example', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-24', 'customfield_10004': 3.0}\"\n",
      "Updating issue \"PP-977\" with \"{'summary': 'Implement get_careunit_benchmarks in SQLAnalyticalService', 'description': 'see pandas and 1.24.30 implementation as example', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-24', 'customfield_10004': 3.0}\"\n",
      "Updating issue \"PP-978\" with \"{'summary': 'Implement get_all_service_line_ids in SQLAnalyticalService', 'description': 'use get_service_unit_ids method result from DataCommons', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.625}\"\n",
      "Updating issue \"PP-979\" with \"{'summary': 'Implement get_unique_drgs in SQLAnalyticalService', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.75}\"\n",
      "Updating issue \"PP-540\" with \"{'summary': 'ServiceLine API', 'description': 'see design', 'customfield_11701': '2021-04-13', 'customfield_11702': '2021-04-14'}\"\n",
      "Updating issue \"PP-980\" with \"{'summary': 'Handle parent_node = None for service line nodes in find_child_nodes_method', 'description': 'implement unit test to cover this case', 'customfield_11701': '2021-04-13', 'customfield_11702': '2021-04-14', 'customfield_10004': 0.5}\"\n",
      "Updating issue \"PP-981\" with \"{'summary': 'Implement filteredServiceLines, filteredClinicalEpisodes and filteredDRGs endpoints', 'description': 'see design', 'customfield_11701': '2021-04-13', 'customfield_11702': '2021-02-24', 'customfield_10004': 3.0}\"\n",
      "Updating issue \"PP-580\" with \"{'summary': 'Implement searchAllDiagnose endpoint', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 2.5}\"\n",
      "Updating issue \"PP-542\" with \"{'summary': 'Location API', 'description': 'Move code and data from existing P2v2 implementation to P2v3', 'customfield_11701': '2021-04-01', 'customfield_11702': '2021-04-06'}\"\n",
      "Updating issue \"PP-543\" with \"{'summary': 'Move allUSStates endpoint', 'description': 'Copy data to postgres, move django model from P2v2', 'customfield_11701': '2021-04-02', 'customfield_11702': '2021-04-06', 'customfield_10004': 2.5}\"\n",
      "Updating issue \"PP-584\" with \"{'summary': 'Move usState endpoint', 'description': 'Copy data to postgres, move django model from P2v2', 'customfield_11701': '2021-04-05', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.5}\"\n",
      "Updating issue \"PP-585\" with \"{'summary': 'Move searchUsLocation endpoint', 'description': 'Copy data to postgres, move django model from P2v2', 'customfield_11701': '2021-04-05', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.5}\"\n",
      "Updating issue \"PP-586\" with \"{'summary': 'Move usStateGeoAll endpoint', 'description': 'Copy .json file, make the path configurable', 'customfield_11701': '2021-04-01', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-587\" with \"{'summary': 'Move usCountyGeoForState endpoint', 'description': 'Copy .json file, make the path configurable', 'customfield_11701': '2021-04-01', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.75}\"\n",
      "Updating issue \"PP-588\" with \"{'summary': 'Move usStateGeoSearch', 'description': 'Copy data to postgres, move django model from P2v2', 'customfield_11701': '2021-04-05', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.5}\"\n",
      "Updating issue \"PP-589\" with \"{'summary': 'Move usCountyGeoAll endpoint', 'description': 'Copy data to postgres, move django model from P2v2', 'customfield_11701': '2021-04-05', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.5}\"\n",
      "Updating issue \"PP-590\" with \"{'summary': 'Move locationByRadialLocation endpoint', 'description': 'Copy .json file, make the path configurable', 'customfield_11701': '2021-04-01', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-982\" with \"{'summary': 'Legend ', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23'}\"\n",
      "Updating issue \"PP-983\" with \"{'summary': 'Implement get_legend_data_statistics', 'description': 'see design, prepare unit tests for all combinations of nodes used in the application', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-25', 'customfield_10004': 5.5}\"\n",
      "Updating issue \"PP-984\" with \"{'summary': 'Implement is_top_level method', 'description': 'see design', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.75}\"\n",
      "Updating issue \"PP-985\" with \"{'summary': 'Implement get_all_service_line_ids in PandasAnalyticalService', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-22', 'customfield_10004': 0.5}\"\n",
      "Updating issue \"PP-986\" with \"{'summary': 'Implement get_unique_drgs in PandasAnalyticalService', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 0.75}\"\n",
      "Updating issue \"PP-987\" with \"{'summary': 'Implement get_top_level_nodes', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.125}\"\n",
      "Updating issue \"PP-988\" with \"{'summary': 'Implement calculate_legend_data method', 'description': 'see design, use is_top_level to avoid unnecessary calculations', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-24', 'customfield_10004': 3.0}\"\n",
      "Updating issue \"PP-989\" with \"{'summary': 'Implement format_legend_data method', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-22', 'customfield_10004': 0.5}\"\n",
      "Updating issue \"PP-990\" with \"{'summary': 'Integrate legend data calculation with the caseSummaryCollection endpoint', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23', 'customfield_10004': 1.25}\"\n",
      "Updating issue \"PP-991\" with \"{'summary': 'Miscellaneous', 'description': 'approx est. ~65h', 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-03-02', 'customfield_10004': 16.25}\"\n",
      "Updating issue \"PP-992\" with \"{'summary': 'Distance filter AC/PAC logic', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23'}\"\n",
      "Updating issue \"PP-994\" with \"{'summary': 'LRU-cache (performance)', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23'}\"\n",
      "Updating issue \"PP-995\" with \"{'summary': 'Redis cache (performance)', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23'}\"\n",
      "Updating issue \"PP-996\" with \"{'summary': 'Flexible dataset IDs', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-23'}\"\n",
      "Creating issue \"Snowflake filter size limitation\"\n",
      "{'id': '63442', 'key': 'PP-1036', 'self': 'https://tangramcare.atlassian.net/rest/api/2/issue/63442'}\n",
      "Updating issue \"PP-997\" with \"{'summary': 'Multithreading', 'description': 'see design', 'customfield_11701': '2021-04-08', 'customfield_11702': '2021-04-14'}\"\n",
      "Updating issue \"PP-998\" with \"{'summary': 'Implement AppThreads singleton class', 'description': 'just copy from design', 'customfield_11701': '2021-04-08', 'customfield_11702': '2021-04-08', 'customfield_10004': 0.125}\"\n",
      "Updating issue \"PP-999\" with \"{'summary': 'Refactor code to use AppThreads singleton', 'description': 'instead of creating ad-hoc ThreadPoolExecutors, modify decompose_packed_nodes, find_child_nodes and possibly other methods', 'customfield_11701': '2021-04-14', 'customfield_11702': '2021-04-14', 'customfield_10004': 0.375}\"\n",
      "Updating issue \"PP-356\" with \"{'summary': 'Report View Management', 'description': None, 'customfield_11701': '2021-03-05', 'customfield_11702': '2021-04-09'}\"\n",
      "Updating issue \"PP-357\" with \"{'summary': 'Environment Setup', 'description': 'Setu development environment including DJangoand PGSql', 'customfield_11701': '2021-03-05', 'customfield_11702': '2021-03-16', 'customfield_10004': 5.0}\"\n",
      "Updating issue \"PP-358\" with \"{'summary': 'Define schema.py', 'description': 'Class that defines graphQL queries, endpoints and object structure. Python file will have definition of following ojects. Developer can refer existing P2BE code at p2backend\\\\ReportView\\\\schema.py file.', 'customfield_11701': '2021-03-05', 'customfield_11702': '2021-03-16', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-359\" with \"{'summary': 'Define reportview_api.py', 'description': 'Class that has actual implementation for all end points. Developer can refer p2backend\\\\BigSense\\\\Reportview\\\\reportview_api.py file from existing P2BE code', 'customfield_11701': '2021-03-05', 'customfield_11702': '2021-03-16', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-360\" with \"{'summary': 'Define model.py', 'description': 'Class that defines the Entity Relation of report view as per OLTP database(Postgres)', 'customfield_11701': '2021-03-05', 'customfield_11702': '2021-03-16', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-361\" with \"{'summary': 'Implementing Endpoints', 'description': 'This implementation will have a resolve method in schema.py and corresponding method in reportview_api.py file', 'customfield_11701': '2021-03-05', 'customfield_11702': '2021-03-16', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-362\" with \"{'summary': 'ReportView', 'description': None, 'customfield_11701': '2021-03-05', 'customfield_11702': '2021-03-16', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-363\" with \"{'summary': 'ReportViews', 'description': None, 'customfield_11701': '2021-03-05', 'customfield_11702': '2021-03-16', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-364\" with \"{'summary': 'SearchReportViews', 'description': None, 'customfield_11701': '2021-03-05', 'customfield_11702': '2021-03-16', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-365\" with \"{'summary': 'CreateReportView', 'description': None, 'customfield_11701': '2021-03-05', 'customfield_11702': '2021-03-16', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-366\" with \"{'summary': 'UpdateReportView', 'description': None, 'customfield_11701': '2021-03-05', 'customfield_11702': '2021-03-16', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-367\" with \"{'summary': 'DeleteReportView', 'description': None, 'customfield_11701': '2021-03-05', 'customfield_11702': '2021-03-16', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-516\" with \"{'summary': '[BE] Extract user details from Auth0 token', 'description': None, 'customfield_11701': '2021-03-25', 'customfield_11702': '2021-04-09', 'customfield_10004': 3.0}\"\n",
      "Updating issue \"PP-517\" with \"{'summary': '[BE] Modify Report view endpoints to use user details from Auth0 token', 'description': None, 'customfield_11701': '2021-02-22', 'customfield_11702': '2021-02-24', 'customfield_10004': 3.0}\"\n",
      "Updating issue \"PP-567\" with \"{'summary': 'Integrate analytical endpoints with django', 'description': 'Integrate endpoints with django. To be seen under https://p2v3.ownedoutcomes.com/backend/graphql/ url.\\n\\nList:caseLocationDetails endpoint\\n\\ncaseLobCounts endpoint\\n\\ngetAvailableYears endpoint\\n\\ngetDateTimeStatsForListOfYears endpoint\\n\\nfilteredCareUnitTypes endpoint\\n\\ngetDatasetsInitialFilters\\n\\ngetDateTimesForYear endpoint\\n\\nallDatasets endpoint\\n\\ngetLDSDatasetsIDs endpoint', 'customfield_11701': '2021-03-29', 'customfield_11702': '2021-03-31', 'customfield_10004': 4.0}\"\n",
      "Updating issue \"PP-615\" with \"{'summary': 'Implement mock for users endpoint', 'description': 'Implement user query that returns always same user {  user {    id    name    emailId    __typename  }\\nid could be the same as in query:\\n{\\n\\tReportViews {\\n    viewList {\\n      owner {\\n        id\\n        emailId\\n      }\\n    }\\n  }\\n}', 'customfield_11701': '2021-04-01', 'customfield_11702': '2021-04-01', 'customfield_10004': 0.125}\"\n",
      "!!! FINISHED !!!\n"
     ]
    }
   ],
   "source": [
    "create_or_update_issues(jira=jira, sheet=sheet, schema=schema, project='PP', label=label)\n",
    "print(\"!!! FINISHED !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook.save(filename=filename)\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = {\n",
    "    \"A\": \"wbs\",\n",
    "    \"B\": \"name\",\n",
    "    \"C\": \"description\",\n",
    "    \"D\": \"dependency\",\n",
    "    \"E\": \"estimated_development_time_designer\",\n",
    "    \"F\": \"estimated_development_time_reviewer\",\n",
    "    \"G\": \"estimated_development_time_pm\",\n",
    "    \"H\": \"assigned_developer\",\n",
    "    \"I\": \"estimated_testing_time_tester\",\n",
    "    \"J\": \"estimated_testing_time_pm\",\n",
    "    \"K\": \"assigned_tester\",\n",
    "    \"L\": \"actual_development_time_start\",\n",
    "    \"M\": \"actual_development_time_finish\",\n",
    "    \"N\": \"actual_development_time_duration\",\n",
    "    \"O\": \"commit_statistics_insertions\",\n",
    "    \"P\": \"commit_statistics_deletions\",\n",
    "    \"Q\": \"code_documentation_time\",\n",
    "    \"R\": \"jira_id\",\n",
    "    \"S\": \"commit_id\",\n",
    "    \"T\": \"sprint\",\n",
    "    \"U\": \"comment\"\n",
    "}\n",
    "\n",
    "tasks_to_json = []\n",
    "\n",
    "i = schema['data_offset_row']\n",
    "while sheet[schema['columns']['WBS'] + str(i)].value is not None:\n",
    "    if len(str(sheet[schema['columns']['Name'] + str(i)].value)) != 0:\n",
    "        task = {}\n",
    "        for column in map:\n",
    "            task[map[column]] = str(sheet[column + str(i)].value)\n",
    "        tasks_to_json.append(task)\n",
    "    i = i + 1 \n",
    "\n",
    "print(tasks_to_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font\n",
    "\n",
    "workbook = load_workbook(filename='summary.xlsx')\n",
    "sheet = workbook['Sheet1']\n",
    "\n",
    "i = 1\n",
    "while sheet['A' + str(i)].value is not None:\n",
    "\n",
    "    print(sheet['A' + str(i)].value)\n",
    "    print(sheet['c'+str(i)].value + sheet['d'+str(i)].value + sheet['e'+str(i)].value)\n",
    "    issue = jira.issue_create({\n",
    "            'summary': 'Assign categories to ' + sheet['d'+str(i)].value + ' testcases',\n",
    "            # 'description': sheet[schema['columns']['Description'] + str(index)].value,\n",
    "            'project': {'key': 'PP'},\n",
    "            'issuetype': {'name': 'Sub-task'},\n",
    "            'parent': {'key': 'PP-162'},\n",
    "            # 'Priority': 'priority',\n",
    "            # 'Status': 'status',\n",
    "            # 'Creator': 'creator',\n",
    "            # 'Assignee': 'assignee',\n",
    "        })\n",
    "\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('February 22, 2021, 5:13 PM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "\n",
    "parser.parse(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "parser.parse('2021-5-5') + datetime.timedelta(hours = 5.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}