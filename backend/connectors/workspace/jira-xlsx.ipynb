{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atlassian import Jira\n",
    "from bidict import bidict\n",
    "\n",
    "# jira_info = {\n",
    "#     'url': 'https://tangramcare.atlassian.net/',\n",
    "#     'username': 'xxx@ownedoutcomes.com',\n",
    "#     'api_token': 'xxxxxxxxxxxxxxxx',\n",
    "# }\n",
    "\n",
    "jira_info = {\n",
    "    'url': 'https://tangramcare.atlassian.net/',\n",
    "    'username': 'awaz@ownedoutcomes.com',\n",
    "    'api_token': '6Pu9J7zSN4wBqwqgSREsAE08',\n",
    "}\n",
    "\n",
    "# jira_info = {\n",
    "#     'url': 'https://awaz.atlassian.net/',\n",
    "#     'username': 'wazartur@gmail.com',\n",
    "#     'api_token': 'typYw7sWGOPzOLvtq5Z91BDC',\n",
    "# }\n",
    "\n",
    "\n",
    "# jira standard fields config\n",
    "jira_standard_fields = bidict({\n",
    "    'Summary': 'summary',\n",
    "    'Epic': 'customfield_10008',\n",
    "    'Description': 'description',\n",
    "    'Project': 'project',\n",
    "    'Type': 'issuetype',\n",
    "    'Priority': 'priority',\n",
    "    'Labels': 'labels',\n",
    "    'Status': 'status',\n",
    "    'Creator': 'creator',\n",
    "    'Assignee': 'assignee',\n",
    "    'Parent': 'parent',\n",
    "})\n",
    "\n",
    "jira = Jira(\n",
    "            url=jira_info['url'],\n",
    "            username=jira_info['username'],\n",
    "            password=jira_info['api_token'],\n",
    "            cloud=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100\n0\n"
     ]
    }
   ],
   "source": [
    "issues = jira.jql('project=tt', fields=list(o2_pp_fields.inv.keys()), limit=1000)\n",
    "print(str(issues['maxResults']))\n",
    "print(str(len(issues['issues'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Updating issue \"PP-329\" with \"{'description': 'check', 'customfield_11701': '2021-03-26', 'customfield_11702': '2021-03-27'}\"\n"
     ]
    }
   ],
   "source": [
    "jira.issue_update('PP-329', {\n",
    "            'description': 'check',\n",
    "            'customfield_11701': '2021-03-26',\n",
    "            'customfield_11702': '2021-03-27'\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "\n",
    "workbook = Workbook()\n",
    "sheet = workbook.active\n",
    "\n",
    "sheet[\"A1\"].value = \"Design document:\"\n",
    "sheet[\"C1\"].value = \"Link\"\n",
    "sheet[\"C1\"].hyperlink = \"https://docs.google.com/document/d/1B5RlsVSZdiuKTVAqhrn7xClewqhzrxhliUZd_yIHUBg/edit?usp=sharing\"\n",
    "sheet[\"C1\"].style = \"Hyperlink\"\n",
    "\n",
    "sheet.merge_cells('A3:A4')\n",
    "sheet['A3'].value = 'WBS'\n",
    "\n",
    "sheet.merge_cells('B3:B4')\n",
    "sheet['B3'].value = 'Name'\n",
    "\n",
    "sheet.merge_cells('C3:C4')\n",
    "sheet['C3'].value = 'Description'\n",
    "\n",
    "sheet.merge_cells('D3:D4')\n",
    "sheet['D3'].value = 'Depends on'\n",
    "\n",
    "sheet.merge_cells('E3:G3')\n",
    "sheet['E3'].value = 'Estimated development time [h]'\n",
    "sheet['E4'].value = 'Designer'\n",
    "sheet['F4'].value = 'Reviewer'\n",
    "sheet['G4'].value = 'PM'\n",
    "\n",
    "sheet.merge_cells('H3:H4')\n",
    "sheet['H3'].value = 'Assigned developer'\n",
    "\n",
    "sheet.merge_cells('I3:J3')\n",
    "sheet['I3'].value = 'Estimated testing time [h]'\n",
    "sheet['I4'].value = 'Tester'\n",
    "sheet['J4'].value = 'PM'\n",
    "\n",
    "sheet.merge_cells('K3:K4')\n",
    "sheet['K3'].value = 'Assigned tester'\n",
    "\n",
    "sheet.merge_cells('L3:N3')\n",
    "sheet['L3'].value = 'Actual development time'\n",
    "sheet['L4'].value = 'Start time'\n",
    "sheet['M4'].value = 'Finish time'\n",
    "sheet['N4'].value = 'Duration [h]'\n",
    "\n",
    "sheet.merge_cells('O3:P3')\n",
    "sheet['O3'].value = 'Commit statistics'\n",
    "sheet['O4'].value = 'Insertions'\n",
    "sheet['P4'].value = 'Deletions'\n",
    "\n",
    "sheet.merge_cells('Q3:Q4')\n",
    "sheet['Q3'].value = 'Estimated code documentation time [h]'\n",
    "\n",
    "sheet.merge_cells('R3:R4')\n",
    "sheet['R3'].value = 'Jira ID'\n",
    "\n",
    "sheet.merge_cells('S3:S4')\n",
    "sheet['S3'].value = 'Commit ID'\n",
    "\n",
    "sheet.merge_cells('T3:T4')\n",
    "sheet['T3'].value = 'Comment'\n",
    "\n",
    "\n",
    "workbook.save(filename=\"hello_world.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def datetime_to_date_converter(date):\n",
    "    from datetime import datetime\n",
    "    from dateutil import parser\n",
    "    return parser.parse(date).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def get_schema_from_sheet(sheet): # TODO schema validation\n",
    "    schema = {}\n",
    "    schema['offset_row'] = 1 # offset of WBS: TODO search for WBS\n",
    "    schema['offset_col'] = 0 # offset of WBS: TODO search for WBS\n",
    "    # schema['header_1'] = [i.value for i in sheet['1']] # TODO apply offsets\n",
    "    # schema['header_2'] = [i.value for i in sheet['2']] # TODO apply offsets\n",
    "    # schema['map_to_jira'] = { # TODO something with history (start, finish, duration columns)\n",
    "    #     'Name': 'summary',\n",
    "    #     'Description': 'description',\n",
    "    #     'Jira ID': 'key',\n",
    "    # }\n",
    "\n",
    "\n",
    "    # schema['columns'] = { # TODO make it dynamic\n",
    "    #     'WBS': 'A',\n",
    "    #     'Name': 'B',\n",
    "    #     'Description': 'C',\n",
    "    #     'Depends on': 'D',\n",
    "    #     'Estimate PM': 'G',\n",
    "    #     'Jira ID': 'R',\n",
    "    #     'Start time': 'L',\n",
    "    #     'Finish time': 'M',\n",
    "    #     'Duration [h]': 'N'\n",
    "    # }\n",
    "    # schema['data_offset_row'] = 3\n",
    "    \n",
    "    schema['columns'] = { # TODO make it dynamic\n",
    "        'WBS': 'A',\n",
    "        'Name': 'B',\n",
    "        'Description': 'C',\n",
    "        'Depends on': 'D',\n",
    "        'Estimate PM': 'H',\n",
    "        'Jira ID': 'O',\n",
    "        'Start time': 'J',\n",
    "        'Finish time': 'K',\n",
    "        'Duration [h]': 'L'\n",
    "    }\n",
    "    schema['data_offset_row'] = 3\n",
    "\n",
    "    return schema\n",
    "\n",
    "\n",
    "def get_default_schema_from_template_xlsx(input_template_file = 'template.xlsx', output_schema_file = None):\n",
    "    from openpyxl import load_workbook\n",
    "    import json\n",
    "    workbook = load_workbook(filename=input_template_file)\n",
    "    sheet = workbook['Tasks']\n",
    "\n",
    "    schema = get_schema_from_sheet(sheet)\n",
    "\n",
    "    if output_schema_file == None:\n",
    "        return schema\n",
    "    else:\n",
    "        json.dump(schema, open(output_schema_file, 'w'))\n",
    "\n",
    "\n",
    "def get_issues_from_jira_and_create_xlsx_document_from_template(jira, output_file, project, label, input_template_file = 'template.xlsx'):\n",
    "    from openpyxl import load_workbook\n",
    "    import json\n",
    "    workbook = load_workbook(filename=input_template_file)\n",
    "    sheet = workbook['Tasks']\n",
    "\n",
    "    schema = get_schema_from_sheet(sheet)\n",
    "\n",
    "    issues = jira.jql('project=' + str(project), fields=list(jira_standard_fields.inv.keys()), limit=1000)\n",
    "    # issues = jira.jql('project=' + str(project) + ' and labels=' + str(label), fields=list(jira_standard_fields.inv.keys()), limit=1000)\n",
    "\n",
    "    # TODO\n",
    "\n",
    "\n",
    "def xlsx_to_jira(jira, project, label, input_filename):\n",
    "    from openpyxl import load_workbook\n",
    "    \n",
    "    workbook = load_workbook(filename=input_template_file)\n",
    "    sheet = workbook['Tasks']\n",
    "\n",
    "    schema = get_schema_from_sheet(sheet)\n",
    "    \n",
    "\n",
    "def wbs_regex_check(string, separator = '.'):\n",
    "    import re\n",
    "    return True if re.match('\\A([0-9]+\\\\' + separator + '?)+\\Z', string) else False\n",
    "\n",
    "\n",
    "def wbs_regex_task(string):\n",
    "    import re\n",
    "    return True if re.match('\\A[0-9]+\\Z', string) else False\n",
    "\n",
    "\n",
    "def check_wbs_level(wbs, separator = '.'):\n",
    "    return len(wbs.split(separator))\n",
    "\n",
    "\n",
    "def get_wbs_ancestor(wbs, separator = '.'):\n",
    "    if len(wbs.split(wbs)) == 1:\n",
    "        return wbs.split(wbs)[0]\n",
    "    else:\n",
    "        return '.'.join(wbs.split('.')[0:-1])\n",
    "\n",
    "\n",
    "def check_if_successor(wbs, successor):\n",
    "    wbs_split = wbs.split('.')\n",
    "    successor_split = successor.split('.')\n",
    "    if len(wbs_split) >= len(successor_split):\n",
    "        return False\n",
    "    for i in range(len(wbs_split)):\n",
    "        if wbs_split[i] != successor_split[i]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def get_wbs_lowest_level_task_number(wbs, separator = '.'):\n",
    "    return wbs.split(separator)[-1]\n",
    "\n",
    "\n",
    "def expand_wbs_range(start, finish, separator = '.'):\n",
    "    if check_wbs_level(start, separator) != check_wbs_level(finish, separator):\n",
    "        print('ERROR: WBS range level differs: ', start, ' - ', finish)\n",
    "        return []\n",
    "    if get_wbs_ancestor(start, separator) != get_wbs_ancestor(finish, separator):\n",
    "        print('ERROR: WBS range ancestor differs: ', start, ' - ', finish)\n",
    "        return []\n",
    "    lowest_level_task = list(range(int(get_wbs_lowest_level_task_number(start, separator)), 1 + int(get_wbs_lowest_level_task_number(finish, separator))))\n",
    "    wbs_tasks = []\n",
    "    for i in lowest_level_task:\n",
    "        if get_wbs_ancestor(start, separator) == '':\n",
    "            wbs_tasks.append(str(i))\n",
    "        else:\n",
    "            wbs_tasks.append(get_wbs_ancestor(start, separator) + '.' + str(i))\n",
    "    return wbs_tasks\n",
    "    \n",
    "\n",
    "def parse_dependencies(dependency_str, wbs_separator = '.'):\n",
    "    wbs_tasks = []\n",
    "    for i in str(dependency_str).split(','):\n",
    "        if wbs_regex_check(i.strip(), wbs_separator):\n",
    "            wbs_tasks.append(i)\n",
    "        else:\n",
    "            range = i.split('-')\n",
    "            if len(range) != 2:\n",
    "                print(\"ERROR: It is not a range: \", range)\n",
    "                continue\n",
    "            if wbs_regex_check(range[0].strip(), wbs_separator) == False or wbs_regex_check(range[1].strip(), wbs_separator) == False:\n",
    "                print(\"ERROR: It is not a range: \", range)\n",
    "                continue\n",
    "            wbs_tasks = wbs_tasks + expand_wbs_range(range[0].strip(), range[1].strip(), wbs_separator)\n",
    "    return wbs_tasks\n",
    "\n",
    "\n",
    "def get_value_for_wbs(schema, wbs, column_name):\n",
    "    i = schema['data_offset_row']\n",
    "    while sheet[schema['columns']['WBS'] + str(i)].value is not None:\n",
    "        if wbs == str(sheet[schema['columns']['WBS'] + str(i)].value):\n",
    "            return str(sheet[schema['columns'][column_name] + str(i)].value)\n",
    "        i = i + 1 \n",
    "    return None\n",
    "\n",
    "\n",
    "def get_jira_key_for_wbs(schema, wbs):\n",
    "    i = schema['data_offset_row']\n",
    "    while sheet[schema['columns']['WBS'] + str(i)].value is not None:\n",
    "        if wbs == str(sheet[schema['columns']['WBS'] + str(i)].value):\n",
    "            return str(sheet[schema['columns']['Jira ID'] + str(i)].value)\n",
    "        i = i + 1 \n",
    "    return None\n",
    "\n",
    "\n",
    "def get_start_finish_from_child(schema, wbs):\n",
    "    from dateutil import parser\n",
    "    min = None\n",
    "    max = None\n",
    "    i = schema['data_offset_row']\n",
    "    while sheet[schema['columns']['WBS'] + str(i)].value is not None:\n",
    "        if check_if_successor(wbs, str(sheet[schema['columns']['WBS'] + str(i)].value)):\n",
    "\n",
    "            if min is None and sheet[schema['columns']['Start time'] + str(i)].value is not None:\n",
    "                min = parser.parse(sheet[schema['columns']['Start time'] + str(i)].value)\n",
    "            if max is None and sheet[schema['columns']['Finish time'] + str(i)].value is not None:\n",
    "                max = parser.parse(sheet[schema['columns']['Finish time'] + str(i)].value)\n",
    "\n",
    "            if sheet[schema['columns']['Start time'] + str(i)].value is not None: \n",
    "                if parser.parse(sheet[schema['columns']['Start time'] + str(i)].value) < min:\n",
    "                    min = parser.parse(sheet[schema['columns']['Start time'] + str(i)].value)\n",
    "            if sheet[schema['columns']['Finish time'] + str(i)].value is not None: \n",
    "                if parser.parse(sheet[schema['columns']['Finish time'] + str(i)].value) > max:\n",
    "                    max = parser.parse(sheet[schema['columns']['Finish time'] + str(i)].value)\n",
    "\n",
    "        i = i + 1 \n",
    "    return min, max\n",
    "\n",
    "\n",
    "def get_min_from_start(schema):\n",
    "    from dateutil import parser\n",
    "    min = None\n",
    "    i = schema['data_offset_row']\n",
    "    while sheet[schema['columns']['WBS'] + str(i)].value is not None:\n",
    "        if min is None and sheet[schema['columns']['Start time'] + str(i)].value is not None:\n",
    "            min = parser.parse(sheet[schema['columns']['Start time'] + str(i)].value)\n",
    "\n",
    "        if sheet[schema['columns']['Start time'] + str(i)].value is not None: \n",
    "            if parser.parse(sheet[schema['columns']['Start time'] + str(i)].value) < min:\n",
    "                min = parser.parse(sheet[schema['columns']['Start time'] + str(i)].value)\n",
    "\n",
    "        i = i + 1 \n",
    "    return min\n",
    "\n",
    "\n",
    "def create_or_update_issue(jira, schema, index, project, type, label, parent = None):\n",
    "    if sheet[schema['columns']['Jira ID'] + str(index)].value is None: # create issue\n",
    "        issue = jira.issue_create({\n",
    "            'summary': sheet[schema['columns']['Name'] + str(index)].value,\n",
    "            'description': sheet[schema['columns']['Description'] + str(index)].value,\n",
    "            'project': {'key': project},\n",
    "            'issuetype': {'name': type},\n",
    "            'parent': {'key': parent},\n",
    "            'customfield_11701': sheet[schema['columns']['Start time'] + str(index)].value,\n",
    "            'customfield_11702': sheet[schema['columns']['Finish time'] + str(index)].value,\n",
    "            # 'customfield_10004': str(float(sheet[schema['columns']['Estimate PM'] + str(index)].value)/4),\n",
    "            # 'Priority': 'priority',\n",
    "            # 'Status': 'status',\n",
    "            # 'Creator': 'creator',\n",
    "            # 'Assignee': 'assignee',\n",
    "        })\n",
    "        sheet[schema['columns']['Jira ID'] + str(index)].value = issue['key']\n",
    "        sheet[schema['columns']['Jira ID'] + str(index)].hyperlink = jira.url + '/browse/' + issue['key']\n",
    "        sheet[schema['columns']['Jira ID'] + str(index)].font = Font(underline='single', color='0000FF')\n",
    "        print(issue)\n",
    "    else:\n",
    "        task_json = {\n",
    "            'summary': sheet[schema['columns']['Name'] + str(index)].value,\n",
    "            'description': sheet[schema['columns']['Description'] + str(index)].value\n",
    "        }\n",
    "\n",
    "        min, max = get_start_finish_from_child(schema, sheet[schema['columns']['WBS'] + str(index)].value)\n",
    "        if min is not None:\n",
    "            task_json['customfield_11701'] = min.strftime(\"%Y-%m-%d\")\n",
    "        if max is not None:\n",
    "            task_json['customfield_11702'] = max.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        if sheet[schema['columns']['Start time'] + str(index)].value is not None and min is None:\n",
    "            task_json['customfield_11701'] = datetime_to_date_converter(sheet[schema['columns']['Start time'] + str(index)].value)\n",
    "        if sheet[schema['columns']['Finish time'] + str(index)].value is not None and max is None:\n",
    "            task_json['customfield_11702'] = datetime_to_date_converter(sheet[schema['columns']['Finish time'] + str(index)].value)\n",
    "\n",
    "        global_min = get_min_from_start(schema)\n",
    "        if 'customfield_11701' not in task_json:\n",
    "            task_json['customfield_11701'] = global_min.strftime(\"%Y-%m-%d\")\n",
    "        if 'customfield_11702' not in task_json:\n",
    "            pass\n",
    "            if sheet[schema['columns']['Estimate PM'] + str(index)].value is not None:\n",
    "                task_json['customfield_11702'] = (global_min + datetime.timedelta(hours = float(sheet[schema['columns']['Estimate PM'] + str(index)].value)*3)).strftime(\"%Y-%m-%d\")\n",
    "            else:\n",
    "                task_json['customfield_11702'] = (global_min + datetime.timedelta(days = 1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "        if sheet[schema['columns']['Duration [h]'] + str(index)].value is not None:\n",
    "            task_json['customfield_10004'] = float(sheet[schema['columns']['Duration [h]'] + str(index)].value)/4\n",
    "        else:\n",
    "            if sheet[schema['columns']['Estimate PM'] + str(index)].value is not None:\n",
    "                task_json['customfield_10004'] = float(sheet[schema['columns']['Estimate PM'] + str(index)].value)/4\n",
    "                \n",
    "        jira.issue_update(sheet[schema['columns']['Jira ID'] + str(index)].value, task_json)\n",
    "\n",
    "    if sheet[schema['columns']['Depends on'] + str(index)].value is not None:\n",
    "        if sheet[schema['columns']['Depends on'] + str(index)].value != '':\n",
    "            for dependent_task_wbs in parse_dependencies(sheet[schema['columns']['Depends on'] + str(index)].value):\n",
    "                fields = {\n",
    "                    \"issuelinks\": [\n",
    "                        {\n",
    "                            \"add\": {\n",
    "                                \"type\": {\n",
    "                                    \"name\": \"Gantt End to Start\",\n",
    "                                    \"inward\": \"has to be done after\",\n",
    "                                    \"outward\": \"has to be done before\"\n",
    "                                },\n",
    "                                \"inwardIssue\": {\n",
    "                                    \"key\": get_jira_key_for_wbs(schema, dependent_task_wbs.strip())\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "                jira.edit_issue(issue_id_or_key=sheet[schema['columns']['Jira ID'] + str(index)].value, fields=fields, notify_users=False)\n",
    "    jira.edit_issue(issue_id_or_key=sheet[schema['columns']['Jira ID'] + str(index)].value, fields={\"labels\": [{\"add\": label}]}, notify_users=False)\n",
    "\n",
    "\n",
    "def create_or_update_issues(jira, sheet, schema, project, label):\n",
    "    i = schema['data_offset_row']\n",
    "    while sheet[schema['columns']['WBS'] + str(i)].value is not None:\n",
    "        wbs = str(sheet[schema['columns']['WBS'] + str(i)].value)\n",
    "        if not wbs_regex_check(wbs):\n",
    "            raise Exception('Problem in WBS number structure: ' + str(wbs))\n",
    "\n",
    "        if wbs_regex_task(wbs):\n",
    "            create_or_update_issue(jira=jira, schema=schema, index=i, project=project, type='Task', label=label)\n",
    "        else:\n",
    "            import re\n",
    "            parent = get_jira_key_for_wbs(schema=schema, wbs=re.match('\\A[0-9]+', wbs)[0])\n",
    "            if parent is None:\n",
    "                raise Exception('Task doesn\\'t have a parent: ' + wbs)\n",
    "            create_or_update_issue(jira=jira, schema=schema, index=i, project=project, type='Sub-task', label=label, parent=parent)\n",
    "        # if i > schema['data_offset_row'] + 5: # for tests purposes\n",
    "        #     return\n",
    "        i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font\n",
    "\n",
    "# filename = 'grouper.xlsx'\n",
    "# label = 'P2_pipelines'\n",
    "\n",
    "# filename = 'p2v3.xlsx'\n",
    "# label = 'P2_v3'\n",
    "\n",
    "filename = 'auth.xlsx'\n",
    "label = 'Authorization'\n",
    "\n",
    "# filename = 'tests.xlsx'\n",
    "# label = 'Tests'\n",
    "\n",
    "workbook = load_workbook(filename=filename)\n",
    "sheet = workbook['Tasks']\n",
    "\n",
    "schema = get_schema_from_sheet(sheet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Updating issue \"PP-458\" with \"{'summary': 'Project configuration', 'description': 'Create a project from a template and add library requirements', 'customfield_11701': '2021-03-17', 'customfield_11702': '2021-03-17', 'customfield_10004': 0.375}\"\n",
      "Updating issue \"PP-485\" with \"{'summary': 'Describing abstract classes', 'description': 'Describe abstract classes and helper classes (like classes in model.py) ', 'customfield_11701': '2021-03-22', 'customfield_11702': '2021-03-22', 'customfield_10004': 1.125}\"\n",
      "Updating issue \"PP-311\" with \"{'summary': 'DatasetStorage mock implementation', 'description': 'Implement mock implementation of DatasetStorage for use in tests (documentation).', 'customfield_11701': '2021-03-17', 'customfield_11702': '2021-03-17', 'customfield_10004': 0.5}\"\n",
      "Updating issue \"PP-312\" with \"{'summary': 'Access mock implementation', 'description': 'Implement mock implementation of Access for use in tests (documentation).', 'customfield_11701': '2021-03-17', 'customfield_11702': '2021-03-22', 'customfield_10004': 5.0}\"\n",
      "Updating issue \"PP-313\" with \"{'summary': 'DatasetManager implementation', 'description': 'implement the final version of the class according to the documentation (only class with methods without graphql)', 'customfield_11701': '2021-03-23', 'customfield_11702': '2021-03-24', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-314\" with \"{'summary': 'Implement get()', 'description': 'implement method according to the documentation', 'customfield_11701': '2021-03-23', 'customfield_11702': '2021-03-24', 'customfield_10004': 0.5715}\"\n",
      "Updating issue \"PP-315\" with \"{'summary': 'Implement share()', 'description': 'implement method according to the documentation', 'customfield_11701': '2021-03-23', 'customfield_11702': '2021-03-24', 'customfield_10004': 0.5715}\"\n",
      "Updating issue \"PP-316\" with \"{'summary': 'Implement unshare()', 'description': 'implement method according to the documentation', 'customfield_11701': '2021-03-23', 'customfield_11702': '2021-03-24', 'customfield_10004': 0.5715}\"\n",
      "Updating issue \"PP-317\" with \"{'summary': 'Implement register()', 'description': 'implement method according to the documentation', 'customfield_11701': '2021-03-23', 'customfield_11702': '2021-03-24', 'customfield_10004': 0.5715}\"\n",
      "Updating issue \"PP-318\" with \"{'summary': 'Implement remove()', 'description': 'implement method according to the documentation', 'customfield_11701': '2021-03-23', 'customfield_11702': '2021-03-24', 'customfield_10004': 0.5715}\"\n",
      "Updating issue \"PP-486\" with \"{'summary': 'Implement add_user()', 'description': 'implement method according to the documentation', 'customfield_11701': '2021-03-23', 'customfield_11702': '2021-03-24', 'customfield_10004': 0.5715}\"\n",
      "Updating issue \"PP-487\" with \"{'summary': 'Implement add_parameter()', 'description': 'implement method according to the documentation', 'customfield_11701': '2021-03-23', 'customfield_11702': '2021-03-24', 'customfield_10004': 0.5715}\"\n",
      "Updating issue \"PP-319\" with \"{'summary': 'GraphQL server implementation', 'description': None, 'customfield_11701': '2021-03-25', 'customfield_11702': '2021-03-26', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-320\" with \"{'summary': 'Create model', 'description': 'You have to create a model the chosen technology (graphene) and pass all the requiered objects to it. ', 'customfield_11701': '2021-03-25', 'customfield_11702': '2021-03-26', 'customfield_10004': 0.25}\"\n",
      "Updating issue \"PP-321\" with \"{'summary': 'Implement get() endpoint', 'description': 'create a graphql endpoint according to the documentation with filters', 'customfield_11701': '2021-03-25', 'customfield_11702': '2021-03-26', 'customfield_10004': 0.25}\"\n",
      "Updating issue \"PP-322\" with \"{'summary': 'Implement share() endpoint', 'description': 'create a graphql endpoint according to the documentation', 'customfield_11701': '2021-03-25', 'customfield_11702': '2021-03-26', 'customfield_10004': 0.25}\"\n",
      "Updating issue \"PP-323\" with \"{'summary': 'Implement unshare() endpoint', 'description': 'create a graphql endpoint according to the documentation', 'customfield_11701': '2021-03-25', 'customfield_11702': '2021-03-26', 'customfield_10004': 0.25}\"\n",
      "Updating issue \"PP-324\" with \"{'summary': 'Implement register() endpoint', 'description': 'create a graphql endpoint according to the documentation', 'customfield_11701': '2021-03-25', 'customfield_11702': '2021-03-26', 'customfield_10004': 0.25}\"\n",
      "Updating issue \"PP-325\" with \"{'summary': 'Implement remove() endpoint', 'description': 'create a graphql endpoint according to the documentation', 'customfield_11701': '2021-03-25', 'customfield_11702': '2021-03-26', 'customfield_10004': 0.25}\"\n",
      "Updating issue \"PP-488\" with \"{'summary': 'Implement add_user() endpoint', 'description': 'create a graphql endpoint according to the documentation', 'customfield_11701': '2021-03-25', 'customfield_11702': '2021-03-26', 'customfield_10004': 0.25}\"\n",
      "Updating issue \"PP-489\" with \"{'summary': 'Implement add_parameter() endpoint', 'description': 'create a graphql endpoint according to the documentation', 'customfield_11701': '2021-03-25', 'customfield_11702': '2021-03-26', 'customfield_10004': 0.25}\"\n",
      "Updating issue \"PP-326\" with \"{'summary': 'Access on SQLAlchemy implementation', 'description': 'create models in sqlalchemy and implement abstract methods from access class.Create a model according to sql queries', 'customfield_11701': '2021-03-26', 'customfield_11702': '2021-04-02', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-327\" with \"{'summary': 'implement the model', 'description': 'create a model according to sql queries', 'customfield_11701': '2021-03-26', 'customfield_11702': '2021-04-02', 'customfield_10004': 9.0}\"\n",
      "Updating issue \"PP-544\" with \"{'summary': 'Integration with Auth0', 'description': 'integration with Auth0', 'customfield_11701': '2021-04-02', 'customfield_11702': '2021-04-02', 'customfield_10004': 1.0}\"\n",
      "Updating issue \"PP-490\" with \"{'summary': 'Admin panel implementation', 'description': 'Implement the admin panel using the Flask-Admin library', 'customfield_11701': '2021-03-17', 'customfield_11702': '2021-03-19', 'customfield_10004': 4.0}\"\n",
      "Updating issue \"PP-491\" with \"{'summary': 'Flask integration', 'description': 'Integrate the flask server with sqlalchemy and graphene ', 'customfield_11701': '2021-04-02', 'customfield_11702': '2021-04-06', 'customfield_10004': 2.0}\"\n",
      "Updating issue \"PP-492\" with \"{'summary': 'DatasetStorage implementation', 'description': 'Implement implementation of DatasetStoage with selected warehouse (snowflake)', 'customfield_11701': '2021-03-17', 'customfield_11702': '2021-03-18', 'customfield_10004': 2.0}\"\n",
      "Updating issue \"PP-619\" with \"{'summary': 'Add readme', 'description': 'Add instructions on how to initialize and how to start the server', 'customfield_11701': '2021-03-17', 'customfield_11702': '2021-03-17', 'customfield_10004': 0.0}\"\n",
      "Updating issue \"PP-620\" with \"{'summary': 'Improve technical documentation ', 'description': 'Adapt the technical documentation to the changes that were made during the implementation', 'customfield_11701': '2021-03-17', 'customfield_11702': '2021-03-17', 'customfield_10004': 0.0}\"\n",
      "Creating issue \"Implement graphql client\"\n",
      "{'id': '63089', 'key': 'PP-701', 'self': 'https://tangramcare.atlassian.net/rest/api/2/issue/63089'}\n",
      "Creating issue \"Create a python library\"\n",
      "{'id': '63090', 'key': 'PP-702', 'self': 'https://tangramcare.atlassian.net/rest/api/2/issue/63090'}\n",
      "Creating issue \"Research about deploying flask server on production\"\n",
      "{'id': '63091', 'key': 'PP-703', 'self': 'https://tangramcare.atlassian.net/rest/api/2/issue/63091'}\n"
     ]
    }
   ],
   "source": [
    "create_or_update_issues(jira=jira, sheet=sheet, schema=schema, project='PP', label=label)\n",
    "print(\"!!! FINISHED !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook.save(filename=filename)\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'wbs': '0', 'name': 'Project configuration', 'description': 'Create a project from a template and add library requirements', 'dependency': 'None', 'estimated_development_time_designer': '1.5', 'estimated_development_time_reviewer': '1', 'estimated_development_time_pm': '1', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': '1.5', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-458', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '1', 'name': 'Describing abstract classes', 'description': 'Describe abstract classes and helper classes (like classes in model.py) ', 'dependency': '0', 'estimated_development_time_designer': '1', 'estimated_development_time_reviewer': 'None', 'estimated_development_time_pm': 'None', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-485', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '2', 'name': 'DatasetStorage mock implementation', 'description': 'Implement mock implementation of DatasetStorage for use in tests (documentation).', 'dependency': '0, 1', 'estimated_development_time_designer': '2', 'estimated_development_time_reviewer': '2', 'estimated_development_time_pm': '4', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': '2', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-311', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '3', 'name': 'Access mock implementation', 'description': 'Implement mock implementation of Access for use in tests (documentation).', 'dependency': '0, 1', 'estimated_development_time_designer': '4', 'estimated_development_time_reviewer': '4', 'estimated_development_time_pm': '4', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-312', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '4', 'name': 'DatasetManager implementation', 'description': 'implement the final version of the class according to the documentation (only class with methods without graphql)', 'dependency': '2, 3', 'estimated_development_time_designer': 'None', 'estimated_development_time_reviewer': 'None', 'estimated_development_time_pm': 'None', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-313', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '4.1', 'name': 'Implement get()', 'description': 'implement method according to the documentation', 'dependency': 'None', 'estimated_development_time_designer': '5', 'estimated_development_time_reviewer': '6', 'estimated_development_time_pm': '8', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-314', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '4.2', 'name': 'Implement share()', 'description': 'implement method according to the documentation', 'dependency': 'None', 'estimated_development_time_designer': '1.5', 'estimated_development_time_reviewer': '1.5', 'estimated_development_time_pm': '2', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-315', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '4.3', 'name': 'Implement unshare()', 'description': 'implement method according to the documentation', 'dependency': 'None', 'estimated_development_time_designer': '1.5', 'estimated_development_time_reviewer': '1.5', 'estimated_development_time_pm': '2', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-316', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '4.4', 'name': 'Implement register()', 'description': 'implement method according to the documentation', 'dependency': 'None', 'estimated_development_time_designer': '1.5', 'estimated_development_time_reviewer': '1.5', 'estimated_development_time_pm': '2', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-317', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '4.5', 'name': 'Implement remove()', 'description': 'implement method according to the documentation', 'dependency': 'None', 'estimated_development_time_designer': '1.5', 'estimated_development_time_reviewer': '1.5', 'estimated_development_time_pm': '2', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-318', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '4.6', 'name': 'Implement add_user()', 'description': 'implement method according to the documentation', 'dependency': 'None', 'estimated_development_time_designer': '1.5', 'estimated_development_time_reviewer': '1.5', 'estimated_development_time_pm': '2', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-486', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '4.7', 'name': 'Implement add_parameter()', 'description': 'implement method according to the documentation', 'dependency': 'None', 'estimated_development_time_designer': '1.5', 'estimated_development_time_reviewer': '1.5', 'estimated_development_time_pm': '2', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-487', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '5', 'name': 'GraphQL server implementation', 'description': 'None', 'dependency': '4', 'estimated_development_time_designer': 'None', 'estimated_development_time_reviewer': 'None', 'estimated_development_time_pm': 'None', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-319', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '5.1', 'name': 'Create model', 'description': 'You have to create a model the chosen technology (graphene) and pass all the requiered objects to it. ', 'dependency': 'None', 'estimated_development_time_designer': '4', 'estimated_development_time_reviewer': '6', 'estimated_development_time_pm': '8', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-320', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '5.2', 'name': 'Implement get() endpoint', 'description': 'create a graphql endpoint according to the documentation with filters', 'dependency': '5.1', 'estimated_development_time_designer': '5', 'estimated_development_time_reviewer': '6', 'estimated_development_time_pm': '8', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-321', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '5.3', 'name': 'Implement share() endpoint', 'description': 'create a graphql endpoint according to the documentation', 'dependency': '5.1', 'estimated_development_time_designer': '2', 'estimated_development_time_reviewer': '2', 'estimated_development_time_pm': '2', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-322', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '5.4', 'name': 'Implement unshare() endpoint', 'description': 'create a graphql endpoint according to the documentation', 'dependency': '5.1', 'estimated_development_time_designer': '2', 'estimated_development_time_reviewer': '2', 'estimated_development_time_pm': '2', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-323', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '5.5', 'name': 'Implement register() endpoint', 'description': 'create a graphql endpoint according to the documentation', 'dependency': '5.1', 'estimated_development_time_designer': '2', 'estimated_development_time_reviewer': '2', 'estimated_development_time_pm': '2', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-324', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '5.6', 'name': 'Implement remove() endpoint', 'description': 'create a graphql endpoint according to the documentation', 'dependency': '5.1', 'estimated_development_time_designer': '2', 'estimated_development_time_reviewer': '2', 'estimated_development_time_pm': '2', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-325', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '5.7', 'name': 'Implement add_user() endpoint', 'description': 'create a graphql endpoint according to the documentation', 'dependency': '5.1', 'estimated_development_time_designer': '2', 'estimated_development_time_reviewer': '2', 'estimated_development_time_pm': '2', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-488', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '5.8', 'name': 'Implement add_parameter() endpoint', 'description': 'create a graphql endpoint according to the documentation', 'dependency': '5.1', 'estimated_development_time_designer': '2', 'estimated_development_time_reviewer': '2', 'estimated_development_time_pm': '2', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-489', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '6', 'name': 'Access on SQLAlchemy implementation', 'description': 'create models in sqlalchemy and implement abstract methods from access class.Create a model according to sql queries', 'dependency': '3', 'estimated_development_time_designer': '8', 'estimated_development_time_reviewer': '8', 'estimated_development_time_pm': '12', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-326', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '7', 'name': 'Admin panel implementation', 'description': 'Implement the admin panel using the Flask-Admin library', 'dependency': '5', 'estimated_development_time_designer': '6', 'estimated_development_time_reviewer': '8', 'estimated_development_time_pm': '16', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-490', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '8', 'name': 'Flask integration', 'description': 'Integrate the flask server with sqlalchemy and graphene ', 'dependency': '5, 6', 'estimated_development_time_designer': '4', 'estimated_development_time_reviewer': '6', 'estimated_development_time_pm': '8', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-491', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}, {'wbs': '9', 'name': 'DatasetStorage implementation', 'description': 'Implement implementation of DatasetStoage with selected warehouse (snowflake)', 'dependency': '2', 'estimated_development_time_designer': '4', 'estimated_development_time_reviewer': '4', 'estimated_development_time_pm': '8', 'assigned_developer': 'None', 'estimated_testing_time_tester': 'None', 'estimated_testing_time_pm': 'None', 'assigned_tester': 'None', 'actual_development_time_start': 'None', 'actual_development_time_finish': 'None', 'actual_development_time_duration': 'None', 'commit_statistics_insertions': 'None', 'commit_statistics_deletions': 'None', 'code_documentation_time': 'None', 'jira_id': 'PP-492', 'commit_id': 'None', 'sprint': 'None', 'comment': 'None'}]\n"
     ]
    }
   ],
   "source": [
    "map = {\n",
    "    \"A\": \"wbs\",\n",
    "    \"B\": \"name\",\n",
    "    \"C\": \"description\",\n",
    "    \"D\": \"dependency\",\n",
    "    \"E\": \"estimated_development_time_designer\",\n",
    "    \"F\": \"estimated_development_time_reviewer\",\n",
    "    \"G\": \"estimated_development_time_pm\",\n",
    "    \"H\": \"assigned_developer\",\n",
    "    \"I\": \"estimated_testing_time_tester\",\n",
    "    \"J\": \"estimated_testing_time_pm\",\n",
    "    \"K\": \"assigned_tester\",\n",
    "    \"L\": \"actual_development_time_start\",\n",
    "    \"M\": \"actual_development_time_finish\",\n",
    "    \"N\": \"actual_development_time_duration\",\n",
    "    \"O\": \"commit_statistics_insertions\",\n",
    "    \"P\": \"commit_statistics_deletions\",\n",
    "    \"Q\": \"code_documentation_time\",\n",
    "    \"R\": \"jira_id\",\n",
    "    \"S\": \"commit_id\",\n",
    "    \"T\": \"sprint\",\n",
    "    \"U\": \"comment\"\n",
    "}\n",
    "\n",
    "tasks_to_json = []\n",
    "\n",
    "i = schema['data_offset_row']\n",
    "while sheet[schema['columns']['WBS'] + str(i)].value is not None:\n",
    "    if len(str(sheet[schema['columns']['Name'] + str(i)].value)) != 0:\n",
    "        task = {}\n",
    "        for column in map:\n",
    "            task[map[column]] = str(sheet[column + str(i)].value)\n",
    "        tasks_to_json.append(task)\n",
    "    i = i + 1 \n",
    "\n",
    "print(tasks_to_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'213'"
      ]
     },
     "metadata": {},
     "execution_count": 217
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 248
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Creating issue \"Assign categories to View Dashboard testcases\"\n",
      "PP-160\n",
      "Link View Dashboard testcases\n",
      "Creating issue \"Assign categories to Graph View testcases\"\n",
      "PP-160\n",
      "Link Graph View testcases\n",
      "Creating issue \"Assign categories to Map View testcases\"\n",
      "PP-160\n",
      "Link Map View testcases\n",
      "Creating issue \"Assign categories to 2D Graph View testcases\"\n",
      "PP-160\n",
      "Link 2D Graph View testcases\n",
      "Creating issue \"Assign categories to Authentication testcases\"\n",
      "PP-160\n",
      "Link Authentication testcases\n",
      "Creating issue \"Assign categories to General Sidebar Interactions testcases\"\n",
      "PP-160\n",
      "Link General Sidebar Interactions testcases\n",
      "Creating issue \"Assign categories to Dataset Management testcases\"\n",
      "PP-160\n",
      "Link Dataset Management testcases\n",
      "Creating issue \"Assign categories to Location Filter testcases\"\n",
      "PP-160\n",
      "Link Location Filter testcases\n",
      "Creating issue \"Assign categories to Service Line Filter testcases\"\n",
      "PP-160\n",
      "Link Service Line Filter testcases\n",
      "Creating issue \"Assign categories to Entity Filter testcases\"\n",
      "PP-160\n",
      "Link Entity Filter testcases\n",
      "Creating issue \"Assign categories to Time Filter testcases\"\n",
      "PP-160\n",
      "Link Time Filter testcases\n",
      "Creating issue \"Assign categories to Benchmark Panel testcases\"\n",
      "PP-160\n",
      "Link Benchmark Panel testcases\n",
      "Creating issue \"Assign categories to Benchmark Average on Graph testcases\"\n",
      "PP-160\n",
      "Link Benchmark Average on Graph testcases\n",
      "Creating issue \"Assign categories to Benchmark Percenile on Graph testcases\"\n",
      "PP-160\n",
      "Link Benchmark Percenile on Graph testcases\n",
      "Creating issue \"Assign categories to Benchmark Average & Percentile on Map testcases\"\n",
      "PP-160\n",
      "Link Benchmark Average & Percentile on Map testcases\n",
      "Creating issue \"Assign categories to Labels testcases\"\n",
      "PP-160\n",
      "Link Labels testcases\n",
      "Creating issue \"Assign categories to New Graph implementation (Priyanka) testcases\"\n",
      "PP-160\n",
      "Link New Graph implementation (Priyanka) testcases\n",
      "Creating issue \"Assign categories to Smoke Test testcases\"\n",
      "PP-160\n",
      "Link Smoke Test testcases\n"
     ]
    }
   ],
   "source": [
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font\n",
    "\n",
    "workbook = load_workbook(filename='summary.xlsx')\n",
    "sheet = workbook['Sheet1']\n",
    "\n",
    "i = 1\n",
    "while sheet['A' + str(i)].value is not None:\n",
    "\n",
    "    print(sheet['A' + str(i)].value)\n",
    "    print(sheet['c'+str(i)].value + sheet['d'+str(i)].value + sheet['e'+str(i)].value)\n",
    "    issue = jira.issue_create({\n",
    "            'summary': 'Assign categories to ' + sheet['d'+str(i)].value + ' testcases',\n",
    "            # 'description': sheet[schema['columns']['Description'] + str(index)].value,\n",
    "            'project': {'key': 'PP'},\n",
    "            'issuetype': {'name': 'Sub-task'},\n",
    "            'parent': {'key': 'PP-162'},\n",
    "            # 'Priority': 'priority',\n",
    "            # 'Status': 'status',\n",
    "            # 'Creator': 'creator',\n",
    "            # 'Assignee': 'assignee',\n",
    "        })\n",
    "\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "February 22, 2021, 5:13 PM\n"
     ]
    }
   ],
   "source": [
    "print('February 22, 2021, 5:13 PM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Parser must be a string or character stream, not NoneType",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-97d971dbcca3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdateutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[0;32m   1356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparserinfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1358\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDEFAULTPARSER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    644\u001b[0m                                                       second=0, microsecond=0)\n\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipped_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(self, timestr, dayfirst, yearfirst, fuzzy, fuzzy_with_tokens)\u001b[0m\n\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_timelex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[1;33m)\u001b[0m         \u001b[1;31m# Splits the timestr into tokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mskipped_idxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(cls, s)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, instream)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'read'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             raise TypeError('Parser must be a string or character stream, not '\n\u001b[1;32m---> 76\u001b[1;33m                             '{itype}'.format(itype=instream.__class__.__name__))\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Parser must be a string or character stream, not NoneType"
     ]
    }
   ],
   "source": [
    "from dateutil import parser\n",
    "\n",
    "parser.parse(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 5, 5, 5, 30)"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "import datetime\n",
    "parser.parse('2021-5-5') + datetime.timedelta(hours = 5.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}